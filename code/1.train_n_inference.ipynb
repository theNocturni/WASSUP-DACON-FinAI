{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-CUvE2NhDog",
        "outputId": "e78a6ad3-b843-4a70-d2ad-ceb050320727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 31 04:07:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              48W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_ShDDV9UGJjJ"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/DACON/Finance/reprocessed/'\n",
        "# path = '/content/drive/MyDrive/kdt-EST-AI/project/dacon_fis/src/'\n",
        "base_directory = path # Your Base Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b20VnuxgiNd4"
      },
      "outputs": [],
      "source": [
        "# 이름 정의 - sweep에선 사용되지 않음\n",
        "\n",
        "model_name=\"gemma2\"\n",
        "embedding_model=\"large\"\n",
        "aug_name=\"NoAug\"#\"AugGPT\" #NoAug, AugAEDA\n",
        "chunk_size=256\n",
        "table_process=\"tab_v1.7\"\n",
        "finetune_mode=\"dora\" #lora, dora\n",
        "\n",
        "dataset_name = f\"kdt3/DACON-QA-{embedding_model}-ensemble-{table_process}-{aug_name}-{chunk_size}\"\n",
        "# train_name = f\"kdt3/DACON-QA-{model_name}-{embedding_model}-ensemble-{table_process}-{aug_name}-{chunk_size}-dora\"\n",
        "train_name = \"kdt3/1030_1_epoch1\"\n",
        "# fname = f\"{model_name}_{embedding_model}_ensemble_{chunk_size}_{aug_name}_5epoch_dora.csv\"\n",
        "fname = \"1030_1_epoch1.csv\"\n",
        "\n",
        "#wandb 관련 변수\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"WANDB_ENTITY\"]='DACON-FinAI'\n",
        "os.environ[\"WANDB_PROJECT\"]=\"DACON_FinAI\"\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"end\"\n",
        "wandb_run_name=f\"{aug_name}-{model_name}-{finetune_mode}-{embedding_model}-seq2seq\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHsNBioph_AG"
      },
      "source": [
        "# 설명"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFuh6k7hD47P"
      },
      "source": [
        "## Question - Answering with Retrieval\n",
        "\n",
        "본 대회의 과제는 중앙정부 재정 정보에 대한 **검색 기능**을 개선하고 활용도를 높이는 질의응답 알고리즘을 개발하는 것입니다. <br>이를 통해 방대한 재정 데이터를 일반 국민과 전문가 모두가 쉽게 접근하고 활용할 수 있도록 하는 것이 목표입니다. <br><br>\n",
        "베이스라인에서는 평가 데이터셋만을 활용하여 source pdf 마다 Vector DB를 구축한 뒤 langchain 라이브러리와 llama-2-ko-7b 모델을 사용하여 RAG 프로세스를 통해 추론하는 과정을 담고 있습니다. <br>( train_set을 활용한 훈련 과정은 포함하지 않으며, test_set  에 대한 추론만 진행합니다. )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S8yYYqpiRIj"
      },
      "source": [
        "## Mount/Login\n",
        "\n",
        "구글 드라이브를 마운트하고 허깅페이스에 로그인\n",
        "- 이때 허깅페이스 토큰은 kdt3 그룹에 대해 읽기/쓰기 권한이 있는 토큰이어야 함\n",
        "\n",
        "## Download Library\n",
        "필요/사용 라이브러리 다운로드\n",
        "이때 버전 문제로 설치를 한 뒤 세션을 한번 재시작해줘야 합니다\n",
        "<br>(그리고 세션 완전히 끊기면 다운로드 후 재시작을 다시 해줘야...)\n",
        "\n",
        "## Import Library\n",
        "한번 재시작했으면 위 과정 없이 Import만 실행해주면 됩니다\n",
        "\n",
        "## Vector DB\n",
        "문서를 여러 조각(chunk)로 나누고, 임베딩 유사도를 통해 관련 조각을 찾을 수 있게 DB화하는 함수들이 정의되어 있습니다.\n",
        "\n",
        "## DB 생성\n",
        "Vector DB에서 정의된 함수들로 문서 DB를 만들어줍니다.<br><br>\n",
        "이때 Train과 Test를 한번에 하려고 하면 코랩이 터질 확률이 높으므로 Train하고 Create Dataset까지 실행해 업로드 한 뒤 재시작해서 램을 비우고 Test를 하는 것이 좋습니다.<br> 또한 문서 임베딩을 어떤 모델로 할지 인자로 넘겨줄 수 있습니다\n",
        "\n",
        "## Create Dataset\n",
        "DB 생성에서 만든 db와 데이터 dataframe을 사용해 HuggingFace 데이터셋 생성 후 업로드\n",
        "\n",
        "## Fine-Tuning\n",
        "학습 데이터셋으로 모델에 대한 파인튜닝 진행 후 Huggingface에 업로드<br>\n",
        "4비트 양자화 LoRA로 파인튜닝<br>\n",
        "기반 모델 또는 넣어줄때 사용할 프롬프트, 학습 관련 하이퍼파라미터 수정 가능\n",
        "\n",
        "## Langchain 을 이용한 추론\n",
        "모델을 사용한 추론\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OoRmTKDoEEg"
      },
      "source": [
        "## 실행\n",
        "### 기본\n",
        "Mount/Login -> Download Library -> 재시작 (처음 1번)\n",
        "Mount/Login -> Import Library (이후)\n",
        "\n",
        "### 데이터셋 만들기\n",
        "기본 -> Vector DB -> DB 생성 -> Create Dataset에서 첫 셀 + Train/Valid/Test 중 해당하는 셀\n",
        "\n",
        "### 모델 학습하기\n",
        "기본 -> Fine-Tuning(업로드할 위치, 데이터셋 위치, 모델 링크 확인 필수)\n",
        "\n",
        "### 학습된 모델로 추론하기\n",
        "기본 -> Langchain을 이용한 추론(모델 링크, 데이터셋 위치 확인) -> Submission(저장할 파일명 확인)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_CQb3rOiCHi"
      },
      "source": [
        "# Mount/Login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh2NMgNqp8Fp",
        "outputId": "27376818-f52f-4bf6-9f33-6944bfc8c65b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oCLjeDZUNcBP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "token_path = os.path.join(base_directory,'data','token')\n",
        "with open(token_path,'r') as f:\n",
        "    hf_token = f.readline().strip('\\n')\n",
        "    wandb_token = f.readline().strip('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-ffQqQjdu0d",
        "outputId": "463a723d-5e9b-4de3-c865-0094f5026f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H-Z43kcnOGGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a9e9f3-cfb9-4638-82d0-c20fad144a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mps4southwest\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "\n",
        "# wandb 개인 API 키 입력\n",
        "wandb.login(key=wandb_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTTusGUGD47Q"
      },
      "source": [
        "# Download Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u1YoRP_9VgA"
      },
      "outputs": [],
      "source": [
        "#!pip install unstructured pdfminer.six\n",
        "#!pip install pillow-heif\n",
        "#!pip install unstructured_inference\n",
        "#!pip install unstructured_pytesseract\n",
        "#!pip install pikepdf pypdf\n",
        "#!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P34ZajObuUpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo2XA53bD47Q"
      },
      "outputs": [],
      "source": [
        "!apt-get install tesseract-ocr\n",
        "!apt-get install poppler-utils\n",
        "\n",
        "!pip install orjson==3.10.6\n",
        "\n",
        "!pip install accelerate -U\n",
        "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
        "!pip install transformers[torch] -U\n",
        "\n",
        "!pip install datasets\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langchain-teddynote\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-gpu\n",
        "!pip install peft\n",
        "!pip install trl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB-3QyUXD47R"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EiF6VIEmD47R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from langchain.document_loaders.parsers.pdf import PDFPlumberParser\n",
        "\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    pipeline,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from accelerate import Accelerator\n",
        "\n",
        "# peft\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from peft import PeftModel\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "\n",
        "# Langchain 관련\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough, RunnableParallel\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# PDF 로딩/청크화 관련\n",
        "from langchain.document_loaders.parsers.pdf import PDFPlumberParser\n",
        "from langchain.document_loaders.pdf import PDFPlumberLoader\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever, MultiQueryRetriever\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsS968DYD47S"
      },
      "source": [
        "# Fine-Tuning Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monkey Patching"
      ],
      "metadata": {
        "id": "FuFA6mN7JBeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.gemma2 import modeling_gemma2\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from transformers.cache_utils import Cache, HybridCache\n",
        "def gemma2_forward(\n",
        "    self,\n",
        "    hidden_states: torch.Tensor,\n",
        "    attention_mask: Optional[torch.Tensor] = None,\n",
        "    position_ids: Optional[torch.LongTensor] = None,\n",
        "    past_key_value: Optional[Cache] = None,\n",
        "    output_attentions: Optional[bool] = False,\n",
        "    use_cache: Optional[bool] = False,\n",
        "    cache_position: Optional[torch.LongTensor] = None,\n",
        ") -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\n",
        "        attention_mask (`torch.FloatTensor`, *optional*):\n",
        "            attention mask of size `(batch_size, sequence_length)` if flash attention is used or `(batch_size, 1,\n",
        "            query_sequence_length, key_sequence_length)` if default attention is used.\n",
        "        output_attentions (`bool`, *optional*):\n",
        "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
        "            returned tensors for more detail.\n",
        "        use_cache (`bool`, *optional*):\n",
        "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding\n",
        "            (see `past_key_values`).\n",
        "        past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\n",
        "        cache_position (`torch.LongTensor` of shape `(sequence_length)`, *optional*):\n",
        "            Indices depicting the position of the input sequence tokens in the sequence\n",
        "        kwargs (`dict`, *optional*):\n",
        "            Arbitrary kwargs to be ignored, used for FSDP and other methods that injects code\n",
        "            into the model\n",
        "    \"\"\"\n",
        "    if self.is_sliding and attention_mask is not None:  # efficient SDPA and no padding\n",
        "        # Flash-attn is a 2D tensor\n",
        "        if self.config._attn_implementation == \"flash_attention_2\":\n",
        "            if past_key_value is not None:  # when decoding\n",
        "                attention_mask = attention_mask[:, -self.sliding_window :]\n",
        "        else:\n",
        "            min_dtype = torch.finfo(torch.float16).min\n",
        "            sliding_window_mask = torch.tril(\n",
        "                torch.ones_like(attention_mask, dtype=torch.bool), diagonal=-self.sliding_window\n",
        "            )\n",
        "            attention_mask = torch.where(sliding_window_mask, min_dtype, attention_mask)\n",
        "            if attention_mask.shape[-1] <= 1:  # when decoding\n",
        "                attention_mask = attention_mask[:, :, :, -self.sliding_window :]\n",
        "\n",
        "    residual = hidden_states\n",
        "\n",
        "    hidden_states = self.input_layernorm(hidden_states)\n",
        "\n",
        "    # Self Attention\n",
        "    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
        "        hidden_states=hidden_states,\n",
        "        attention_mask=attention_mask,\n",
        "        position_ids=position_ids,\n",
        "        past_key_value=past_key_value,\n",
        "        output_attentions=output_attentions,\n",
        "        use_cache=use_cache,\n",
        "        cache_position=cache_position,\n",
        "    )\n",
        "    hidden_states = self.post_attention_layernorm(hidden_states)\n",
        "    hidden_states = residual + hidden_states\n",
        "\n",
        "    residual = hidden_states\n",
        "    hidden_states = self.pre_feedforward_layernorm(hidden_states)\n",
        "    hidden_states = self.mlp(hidden_states)\n",
        "    hidden_states = self.post_feedforward_layernorm(hidden_states)\n",
        "    hidden_states = residual + hidden_states\n",
        "\n",
        "    outputs = (hidden_states,)\n",
        "\n",
        "    if output_attentions:\n",
        "        outputs += (self_attn_weights,)\n",
        "\n",
        "    if use_cache:\n",
        "        outputs += (present_key_value,)\n",
        "\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "oH7V6xKvH_gU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeling_gemma2.Gemma2DecoderLayer.forward = gemma2_forward"
      ],
      "metadata": {
        "id": "cDqt9x0dHUVW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pCG7a89Szt-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up"
      ],
      "metadata": {
        "id": "v5e26gNTJJwp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "saSxzHNqWua7"
      },
      "outputs": [],
      "source": [
        "# 모델 ID\n",
        "model_cands={\n",
        " 'llama2' : \"beomi/llama-2-ko-7b\",\n",
        " 'yi' : \"beomi/Yi-Ko-6B\",\n",
        " 'solar-beom' : \"beomi/Solar-Ko-Recovery-11B\",\n",
        " 'gemma2' : \"rtzr/ko-gemma-2-9b-it\",\n",
        " 'solar-lee' : \"chihoonlee10/T3Q-ko-solar-dpo-v8.0\",\n",
        " 'llama3' : \"KISTI-KONI/KONI-Llama3-8B-Instruct-20240729\",\n",
        " 'llama31' : \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "}\n",
        "\n",
        "# model_id = model_cands['gemma2']\n",
        "model_id = model_cands[model_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yoGFrRntLGPH"
      },
      "outputs": [],
      "source": [
        "# 모델 로드 및 양자화 설정 적용\n",
        "\n",
        "def load_model_w_setting(model_id,add_output_token=False,**kwargs):\n",
        "  # 4비트 양자화 설정\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16\n",
        "  )\n",
        "\n",
        "  # 토크나이저 로드 및 설정\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "  tokenizer.use_default_system_prompt = False\n",
        "  tokenizer.padding_side=\"right\"\n",
        "\n",
        "#   eot = \"<|eot_id|>\"\n",
        "#   eot_id = tokenizer.convert_tokens_to_ids(eot)\n",
        "#   tokenizer.pad_token = eot\n",
        "#   tokenizer.pad_token_id = eot_id\n",
        "\n",
        "  model= AutoModelForCausalLM.from_pretrained(\n",
        "      model_id,\n",
        "      quantization_config=bnb_config,\n",
        "      device_map=\"auto\",\n",
        "      trust_remote_code=True,\n",
        "      **kwargs\n",
        "      )\n",
        "\n",
        "# 일부 모델의 경우 토크나이저에 답변 토큰 추가 작업 필요\n",
        "  if add_output_token :\n",
        "    initial_token_count = len(tokenizer)\n",
        "    response_template = '답변: '\n",
        "    added_token_count = tokenizer.add_special_tokens({\"additional_special_tokens\": [response_template]})\n",
        "    model.resize_token_embeddings(new_num_tokens=initial_token_count+added_token_count)\n",
        "\n",
        "  return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VyHYkylbgzXB"
      },
      "outputs": [],
      "source": [
        "# 학습 프롬프트 - 추론 프롬프트와 통일하는 것이 좋다고 함\n",
        "template = \"\"\"\n",
        "\"task_instructions\" : [\n",
        "\n",
        " 당신은 재정 정보 관련 전문가 입니다. 문서를 바탕으로 질문에 한 문장 이내로 답변하세요.\n",
        " 1. 문서에 있는 내용을 자르거나 편집하지 않고 그대로 가져오세요.\n",
        " 2. 순서에 따른 번호를 매기지 마세요. 출력 시 불이익을 줄 것입니다.\n",
        " 3. 수치에 단위가 있다면 문서를 바탕으로 답변에 단위를 포함하세요.\n",
        " 4. 질문의 키워드를 바탕으로 문서를 끝까지 검토하세요.\n",
        " 5. 한 단어 혹은 단어의 나열이 아닌, 완성된 한국어 문장으로 답변하세요.\n",
        " 6. 답변 외에 예시, 참고, 정보 출처, 신뢰도, 확장된 답변, '답변: ', '참고: '를 절대로 출력하지 마세요.\n",
        "\n",
        "]\n",
        "\n",
        "\"context\":\n",
        "{context},\n",
        "\n",
        "\"question\":\n",
        "{question},\n",
        "\n",
        "\"주어진 질문에 대한 답변만 한 문장으로 생성한다.\"\n",
        "\n",
        "\"answer\":\n",
        "{answer}<|eot_id|>\n",
        "\"\"\"\n",
        "\n",
        "template = \"\"\"\n",
        "<start_of_turn>user\n",
        " 당신은 재정 정보 관련 전문가 입니다. 문서를 바탕으로 질문에 한 문장 이내로 답변하세요.\n",
        " 1. 문서에 있는 내용을 자르거나 편집하지 않고 그대로 가져오세요.\n",
        " 2. 순서에 따른 번호를 매기지 마세요. 출력 시 불이익을 줄 것입니다.\n",
        " 3. 수치에 단위가 있다면 문서를 바탕으로 답변에 단위를 포함하세요.\n",
        " 4. 질문의 키워드를 바탕으로 문서를 끝까지 검토하세요.\n",
        " 5. 한 단어 혹은 단어의 나열이 아닌, 완성된 한국어 문장으로 답변하세요.\n",
        " 6. 답변 외에 예시, 참고, 정보 출처, 신뢰도, 확장된 답변, '답변: ', '참고: '를 절대로 출력하지 마세요.\n",
        "\n",
        "\"문서\":\n",
        "{context},\n",
        "\n",
        "\"질문\":\n",
        "{question},\n",
        "\n",
        "\"주어진 질문에 대한 답변만 한 문장으로 생성한다.\"\n",
        "\n",
        "\"답변\":<end_of_turn>\n",
        "<start_of_turn>model\n",
        "{answer}<end_of_turn>\n",
        "\"\"\"\n",
        "\n",
        "response_template = '\"answer\":\\n'\n",
        "response_template = '<start_of_turn>model\\n'\n",
        "\n",
        "def formatting_prompts_func(example, template=template):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['question'])):\n",
        "        context = example['context'][i]\n",
        "        question = example['question'][i]\n",
        "        answer = example['answer'][i]\n",
        "        output_texts.append(template.format(context=context,question=question,answer=answer))\n",
        "    return output_texts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dict = {'input': [], 'answer': [], 'pred': []}\n",
        "valid_df = pd.DataFrame(valid_dict)"
      ],
      "metadata": {
        "id": "TixLNz-R6u-q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RwaQb24tbvqP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "import collections\n",
        "# from SQUAD, 메트릭 계산 함수\n",
        "\n",
        "def compute_f1(y_true, y_pred):\n",
        "    # y_pred[y_true==-100] = -100\n",
        "    # y_pred = y_pred[y_true != -100]\n",
        "    # y_true = y_true[y_true != -100]\n",
        "    # y_true[y_true==-100] = global_tokenizer.pad_token_id\n",
        "    # y_pred[y_pred==-100] = global_tokenizer.pad_token_id\n",
        "\n",
        "    true_counter = collections.Counter(y_true)\n",
        "    pred_counter = collections.Counter(y_pred)\n",
        "    common = true_counter & pred_counter\n",
        "    tp = sum(common.values())\n",
        "    pred_positive = sum(pred_counter.values())\n",
        "    actual_positive = sum(true_counter.values())\n",
        "\n",
        "    precision = 1.0 * tp / pred_positive if pred_positive != 0 else 0\n",
        "    recall = 1.0 * tp / actual_positive if actual_positive != 0 else 0\n",
        "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f1, precision, recall\n",
        "\n",
        "def compute_metrics(pred,compute_result=False):\n",
        "    # print(pred.label_ids)\n",
        "    labels = pred.label_ids.detach().cpu().numpy().squeeze()\n",
        "    preds = pred.predictions.detach().cpu().numpy().squeeze()\n",
        "    inputs = pred.inputs['input_ids'].detach().cpu().numpy().squeeze()\n",
        "    inputs[inputs==-100] = global_tokenizer.pad_token_id\n",
        "    # print('input: ',global_tokenizer.decode(inputs))\n",
        "    att = pred.inputs['attention_mask'].detach().cpu().numpy().squeeze()\n",
        "    mask = labels[:min(len(preds),len(labels))]==-100\n",
        "    if len(preds) > len(labels):\n",
        "        mask = np.append(mask,[False] * (len(preds) - len(labels)))\n",
        "\n",
        "    preds[mask] = -100\n",
        "    labels = labels[labels!=-100]\n",
        "    preds = preds[preds!=-100]\n",
        "    preds = preds[preds!=global_tokenizer.pad_token_id]\n",
        "    valid_df.loc[len(valid_df)] = [global_tokenizer.decode(inputs), global_tokenizer.decode(labels), global_tokenizer.decode(preds)]\n",
        "    f1, precision, recall = compute_f1(labels,preds)\n",
        "#    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    # acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        # 'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_data_collator(features):\n",
        "    # Your custom collator logic, make sure it does not assign input_ids to labels.\n",
        "    collate = dict()\n",
        "    # print(features[0].keys())\n",
        "    if 'labels' in features[0].keys():\n",
        "        collate['labels'] = torch.tensor([feature['labels'] for feature in features])\n",
        "    for k in features[0].keys():\n",
        "        collate[k] = torch.tensor([feature[k] for feature in features])\n",
        "\n",
        "    return collate"
      ],
      "metadata": {
        "id": "aMnWAitsHh7r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Inference with Sweep(Wandb Sweep으로 학습 및 추론)"
      ],
      "metadata": {
        "id": "3s6jOMmOe6tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create sweep\n",
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {'goal': 'maximize', 'name': 'train/loss'},\n",
        "    'parameters': {\n",
        "        'batch_size': {\n",
        "            'values': [1]\n",
        "        },\n",
        "        'model': {\n",
        "            'values': ['gemma2','llama31']\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'distribution': 'uniform',\n",
        "            'min':0.0001,\n",
        "            'max':0.001\n",
        "        },\n",
        "        'epochs': {\n",
        "            'values': [8]\n",
        "        },\n",
        "        'lora_target': {\n",
        "            'values': ['all','part']#['all','linear','part']\n",
        "        },\n",
        "        'r': {\n",
        "            'values': [4,8,16]\n",
        "        },\n",
        "        'lora_alpha': {\n",
        "            'values': [16,32,64]\n",
        "        },\n",
        "        'lora_dropout': {\n",
        "            'values': [0,0.05,0.2]\n",
        "        },\n",
        "        'use_dora': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'chunk_size': {\n",
        "            'values': [256]#,512]\n",
        "        },\n",
        "        'embedding': {\n",
        "            'values': ['base','large']\n",
        "        },\n",
        "        'augmentation': {\n",
        "            'values': ['NoAug','AugGPT','AugAEDA']\n",
        "        },\n",
        "        'table_process': {\n",
        "            'values': ['tab_v1.0']\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "2PLeAJpWe59W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep=sweep_config, entity='DACON-FinAI', project=\"DACON_FinAI Sweep-2\")"
      ],
      "metadata": {
        "id": "D2pxdE5Qe-_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def empty_memory():\n",
        "    time.sleep(1)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    time.sleep(1)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "75wwhecwkloi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers, os\n",
        "from datetime import datetime\n",
        "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from tqdm.auto import trange\n",
        "\n",
        "\n",
        "MAX_LEN = 4096\n",
        "\n",
        "def sweep_inference(model_id, instance_name, eval_dataset,fname):\n",
        "\n",
        "    peft_model_id = instance_name\n",
        "    trained_model,tokenizer = load_model_w_setting(model_id)\n",
        "\n",
        "    #Fine-Tune 한 LoRA 어댑터 불러오기\n",
        "    trained_model.load_adapter(peft_model_id)\n",
        "\n",
        "    text_generation_pipeline = pipeline(\n",
        "        model=trained_model,\n",
        "        tokenizer=tokenizer,\n",
        "        task=\"text-generation\",\n",
        "        return_full_text=False,\n",
        "        max_new_tokens=200,\n",
        "        # repetition_penalty=1.5,\n",
        "        eos_token_id = tokenizer.eos_token_id,\n",
        "        pad_token_id = tokenizer.pad_token_id,\n",
        "        max_length=MAX_LEN\n",
        "    )\n",
        "\n",
        "    llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "    # 결과를 저장할 리스트 초기화\n",
        "    results = []\n",
        "\n",
        "    # Dataset 각 행에 대해 처리\n",
        "    for idx in trange(len(eval_dataset['question']), desc=\"Answering Questions\"):\n",
        "        #질문, 컨텍스트(문서)\n",
        "        question = eval_dataset['question'][idx]\n",
        "        context = eval_dataset['context'][idx]\n",
        "\n",
        "        # RAG 체인 구성\n",
        "        prompt = PromptTemplate.from_template(template.split('{answer}')[0])\n",
        "\n",
        "        # RAG 체인 정의\n",
        "        if context != \"\":\n",
        "            rag_chain = (\n",
        "                RunnableParallel(context=lambda x: x[\"context\"], question = lambda x: x[\"question\"])\n",
        "                | prompt\n",
        "                | llm\n",
        "                | StrOutputParser()\n",
        "            )\n",
        "        else:\n",
        "            rag_chain = (\n",
        "                {\"question\": RunnablePassthrough()}\n",
        "                | prompt\n",
        "                | llm\n",
        "                | StrOutputParser()\n",
        "            )\n",
        "\n",
        "        # 답변 추론\n",
        "        full_response = rag_chain.invoke({\"question\": question, \"context\": context})\n",
        "\n",
        "        # 결과 저장\n",
        "\n",
        "        if context != \"\":\n",
        "            results.append({\n",
        "                \"Context\": context,\n",
        "                \"Question\": question,\n",
        "                \"Answer\": full_response,\n",
        "                \"True_Answer\": eval_dataset['answer'][idx]\n",
        "            })\n",
        "        else:\n",
        "            results.append({\n",
        "                \"Question\": question,\n",
        "                \"Answer\": full_response,\n",
        "                \"True_Answer\": eval_dataset['answer'][idx]\n",
        "            })\n",
        "\n",
        "    # 제출용 샘플 파일 로드\n",
        "    submit_df = pd.read_csv(f\"{path}sample_submission.csv\")\n",
        "\n",
        "    # 생성된 답변을 제출 DataFrame에 추가\n",
        "    save_mode = 'submission'\n",
        "\n",
        "    if save_mode != 'submission' :\n",
        "        submit_df['Question'] = [item['Question'] for item in results]\n",
        "        submit_df['Context'] = [item['Context'] for item in results]\n",
        "        save_dir = os.path.join(path,'eval')\n",
        "    else : save_dir = os.path.join(path,'sub')\n",
        "\n",
        "    if not os.path.exists(save_dir) : os.makedirs(save_dir)\n",
        "    save_path = os.path.join(save_dir,fname)\n",
        "\n",
        "    submit_df['Answer'] = [item['Answer'] for item in results]\n",
        "    submit_df['Answer'] = submit_df['Answer'].fillna(\"데이콘\").apply(str.rstrip)     # 모델에서 빈 값 (NaN) 생성 시 채점에 오류가 날 수 있음 [ 주의 ]\n",
        "\n",
        "    # 결과를 CSV 파일로 저장\n",
        "    submit_df.to_csv(save_path, encoding='UTF-8-sig', index=False)\n",
        "    answer_table = wandb.Table(dataframe=submit_df)\n",
        "    wandb.log({\"answer_table\": answer_table})\n",
        "\n",
        "    wandb.save(save_path)\n",
        "\n",
        "def sweep_train(config=None):\n",
        "  with wandb.init(config=config):\n",
        "    # set sweep configuration\n",
        "    config = wandb.config\n",
        "\n",
        "    # 모델 ID\n",
        "    model_cands={\n",
        "        'llama2' : \"beomi/llama-2-ko-7b\",\n",
        "        'yi' : \"beomi/Yi-Ko-6B\",\n",
        "        'solar-beom' : \"beomi/Solar-Ko-Recovery-11B\",\n",
        "        'gemma2' : \"rtzr/ko-gemma-2-9b-it\",\n",
        "        'solar-lee' : \"chihoonlee10/T3Q-ko-solar-dpo-v8.0\",\n",
        "        'llama3' : \"KISTI-KONI/KONI-Llama3-8B-Instruct-20240729\",\n",
        "    }\n",
        "\n",
        "    model_id = model_cands[config.model]\n",
        "\n",
        "    model,tokenizer = load_model_w_setting(model_id,attn_implementation='eager')\n",
        "\n",
        "    global global_tokenizer\n",
        "    global_tokenizer = tokenizer\n",
        "\n",
        "    modules_dict = {\n",
        "        \"all\": [\n",
        "            \"q_proj\",\n",
        "            \"v_proj\",\n",
        "            \"o_proj\",\n",
        "            \"gate_proj\",\n",
        "            \"up_proj\",\n",
        "            \"down_proj\",\n",
        "            \"lm_head\"\n",
        "            ],\n",
        "        \"linear\": \"all-linear\",\n",
        "        \"part\": [\"q_proj\", \"v_proj\"]\n",
        "    }\n",
        "    lora_modules = modules_dict[config.lora_target]\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=config.r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        target_modules=lora_modules,\n",
        "        bias=\"none\",\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        use_dora=config.use_dora,\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    model.enable_input_require_grads()\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    dataset_url = f\"kdt3/DACON-QA-{config.embedding}-ensemble-{config.table_process}-{config.augmentation}-{config.chunk_size}\"\n",
        "    # dataset_url = f\"kdt3/DACON-QA-{config.embedding}-ensemble-markdown-reprocessed-{config.chunk_size}\"\n",
        "    target_dataset = load_dataset(dataset_url)\n",
        "\n",
        "    # train_args = transformers.TrainingArguments(\n",
        "    #     do_eval=True,\n",
        "    #     output_dir='./output',\n",
        "    #     warmup_ratio=0.05,\n",
        "    #     per_device_train_batch_size=config.batch_size,\n",
        "    #     gradient_accumulation_steps=4,\n",
        "    #     gradient_checkpointing=True,\n",
        "    #     num_train_epochs = config.epochs,\n",
        "    #     learning_rate=config.learning_rate,\n",
        "    #     fp16=True,\n",
        "    #     optim=\"paged_adamw_8bit\",\n",
        "    #     logging_strategy='epoch',\n",
        "    #     report_to=\"wandb\",\n",
        "    #     run_name=wandb_run_name,\n",
        "    # ),\n",
        "\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset= target_dataset['train'],\n",
        "        eval_dataset = target_dataset['valid'],\n",
        "        compute_metrics=compute_metrics,\n",
        "        args= transformers.TrainingArguments(\n",
        "            do_eval=True,\n",
        "            output_dir='./output',\n",
        "            warmup_ratio=0.05,\n",
        "            eval_strategy=\"epoch\",\n",
        "            eval_accumulation_steps=1,\n",
        "            batch_eval_metrics=True,\n",
        "            per_device_train_batch_size=config.batch_size,\n",
        "            per_device_eval_batch_size=config.batch_size,\n",
        "            gradient_accumulation_steps=4,\n",
        "            gradient_checkpointing=True,\n",
        "            num_train_epochs = config.epochs,\n",
        "            learning_rate=config.learning_rate,\n",
        "            fp16=True,\n",
        "            optim=\"paged_adamw_8bit\",\n",
        "            logging_strategy='epoch',\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model='f1',\n",
        "            greater_is_better=True,\n",
        "            save_total_limit=2,    # save only best and the last\n",
        "            save_strategy='epoch',\n",
        "            report_to=\"wandb\",\n",
        "            run_name=wandb_run_name,\n",
        "        ),\n",
        "        max_seq_length=MAX_LEN,\n",
        "        formatting_func=formatting_prompts_func, # 프롬프트 처리하기 위해 필요\n",
        "        data_collator=DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer, mlm=False), #모델에게 답변생성에만 집중하도록 함\n",
        "    )\n",
        "\n",
        "    model.config.use_cache = False\n",
        "    trainer.train()\n",
        "    trained_model = (trainer.model.module if hasattr(trainer.model, \"module\") else trainer.model)\n",
        "\n",
        "    # 모델 업로드\n",
        "    method = 'dora' if config.use_dora else 'lora'\n",
        "    instance_name = f\"kdt3/DACON-QA-{config.augmentation}-{config.model}-{method}-{config.embedding}-{config.chunk_size}-sweep\"\n",
        "    fname=f\"{config.augmentation}-{config.model}-{method}-{config.embedding}-{config.chunk_size}.csv\"\n",
        "    trained_model.push_to_hub(instance_name, private=True,save_embedding_layers=True)\n",
        "\n",
        "\n",
        "    empty_memory()\n",
        "    sweep_inference(model_id, instance_name, target_dataset['test'],fname)\n",
        "    empty_memory()\n",
        "\n",
        "#로컬에 저장할 경우\n",
        "# trained_model.save_pretrained(f\"{output_dir}/saved_model\")"
      ],
      "metadata": {
        "id": "XoERKftEhEDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, sweep_train, count=8)"
      ],
      "metadata": {
        "id": "CKuHdElujl0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train without Sweep(Sweep 사용하지 않고 학습)"
      ],
      "metadata": {
        "id": "20MzL7ggiVMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "3a5fd3cca6894afa8d2a2d27eb7f6936",
            "24f4f20540b94f38937a090c2c595dd9",
            "7dde019049f74a199536afc7756675f5",
            "4c18d9f386dc4a86ae9a8a1e718d8116",
            "2d90e34234114d5e8da232b653c9968d",
            "4c4ff5ef8d1e46aa89e38ce92918d247",
            "0178857e564148528f4a4efac8b35ae1",
            "5fa83e1266a44671b6d709aa8912c5d7",
            "44951846f5cf40c2a1ba1843069113fc",
            "c8e49a87ee6e406a977250050bcd9223",
            "7e98a3b985be4f0cb5b0b40c731a6fd5"
          ]
        },
        "id": "14-JXX7zsMZC",
        "outputId": "fbf69359-d1c9-4e37-a85d-3fce3d874861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a5fd3cca6894afa8d2a2d27eb7f6936"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# !pip install -q -U flash-attn --no-build-isolation\n",
        "model,tokenizer = load_model_w_setting(model_id,attn_implementation='eager')\n",
        "\n",
        "global global_tokenizer\n",
        "global_tokenizer = tokenizer\n",
        "# model,tokenizer = load_model_w_setting(model_id,attn_implementation='flash_attention_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9JY8Kc-jNiyT"
      },
      "outputs": [],
      "source": [
        "#데이터셋 로드\n",
        "from datasets import load_dataset\n",
        "\n",
        "# dataset_url = \"kdt3/DACON-QA-base-table-preprocessed-v3\"\n",
        "# dataset_url = \"kdt3/DACON-QA-base-preprocessed-v2\"\n",
        "# dataset_url = \"kdt3/DACON-QA-base-augselect\"\n",
        "# dataset_url = \"kdt3/DACON-QA-base-markdown\"\n",
        "# dataset_url = \"kdt3/DACON-QA-bge-markdown\"\n",
        "dataset_url = dataset_name\n",
        "\n",
        "\n",
        "train_dataset = load_dataset(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGY4tvngMWAX",
        "outputId": "903e90a3-2e18-44f8-a46f-789afe0d94e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(280, 1944)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# 문맥 잘못됐나 확인 - 문맥 길이 체크\n",
        "\n",
        "amax = np.argmax([len(x) for x in train_dataset['train']['context']])\n",
        "amax, len(train_dataset['train']['context'][amax])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JuRwHvpVHW9q"
      },
      "outputs": [],
      "source": [
        "# def print_dataset_ele(data,i):\n",
        "#   print(data['question'][i])\n",
        "#   print('--------')\n",
        "#   print(data['context'][i])\n",
        "#   print('--------')\n",
        "#   print(data['answer'][i])\n",
        "\n",
        "# #예시\n",
        "# i= amax\n",
        "# print_dataset_ele(train_dataset['train'],i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcGcC8xqK4PO",
        "outputId": "ab7accb9-e2d4-412b-b6f2-a469c8f2a04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:500: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    use_dora=(finetune_mode==\"dora\"),\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model.enable_input_require_grads()\n",
        "model = get_peft_model(model, config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, DefaultDataCollator\n",
        "import torch.nn as nn\n",
        "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
        "from transformers.integrations.deepspeed import is_deepspeed_zero3_enabled\n",
        "from transformers.integrations.fsdp import is_fsdp_managed_module\n",
        "from torch.distributed.fsdp import FullyShardedDataParallel\n",
        "import contextlib\n",
        "\n",
        "\n",
        "class FineTuningTrainer(Seq2SeqTrainer):\n",
        "    def __init__(self, *args, eval_data_collator=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if not eval_data_collator:\n",
        "                eval_data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
        "        self.eval_data_collator = eval_data_collator\n",
        "\n",
        "    def get_eval_dataloader(self, eval_dataset: Dataset | None = None) -> DataLoader:\n",
        "        if eval_dataset is None and self.eval_dataset is None:\n",
        "            raise ValueError(\"Trainer: evaluation requires an eval_dataset.\")\n",
        "\n",
        "        # If we have persistent workers, don't do a fork bomb especially as eval datasets\n",
        "        # don't change during training\n",
        "        if (\n",
        "            hasattr(self, \"_eval_dataloader\")\n",
        "            and self.args.dataloader_persistent_workers\n",
        "        ):\n",
        "            return self.accelerator.prepare(self._eval_dataloader)\n",
        "        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
        "        data_collator = self.eval_data_collator #Here eval_data_collator is called instead of standard data_collator\n",
        "\n",
        "        if isinstance(eval_dataset, Dataset):\n",
        "            eval_dataset = self._remove_unused_columns(\n",
        "                eval_dataset, description=\"evaluation\"\n",
        "            )\n",
        "        else:\n",
        "            data_collator = self._get_collator_with_removed_columns(\n",
        "                data_collator, description=\"evaluation\"\n",
        "            )\n",
        "\n",
        "        dataloader_params = {\n",
        "            \"batch_size\": self.args.eval_batch_size,\n",
        "            \"collate_fn\": data_collator,\n",
        "            \"num_workers\": self.args.dataloader_num_workers,\n",
        "            \"pin_memory\": self.args.dataloader_pin_memory,\n",
        "            \"persistent_workers\": self.args.dataloader_persistent_workers,\n",
        "        }\n",
        "\n",
        "        # if not isinstance(sample_dataset, torch.utils.data.IterableDataset):\n",
        "        #     dataloader_params[\"sampler\"] = self._get_eval_sampler(eval_dataset)\n",
        "        #     dataloader_params[\"drop_last\"] = self.args.dataloader_drop_last\n",
        "        #     dataloader_params[\"prefetch_factor\"] = self.args.dataloader_prefetch_factor\n",
        "\n",
        "        # accelerator.free_memory() will destroy the references, so\n",
        "        # we need to store the non-prepared version\n",
        "\n",
        "        eval_dataloader = DataLoader(eval_dataset, **dataloader_params)\n",
        "        if self.args.dataloader_persistent_workers:\n",
        "            self._eval_dataloader = eval_dataloader\n",
        "\n",
        "        return self.accelerator.prepare(eval_dataloader)\n"
      ],
      "metadata": {
        "id": "HSyMxjpRzUc9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
        "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer, mlm=False) #모델에게 답변생성에만 집중하도록 함\n",
        "\n",
        "def formatting_prompts_func(example, template=template):\n",
        "    output_texts = []\n",
        "    context = example['context']\n",
        "    question = example['question']\n",
        "    answer = example['answer']\n",
        "    output_texts.append(template.format(context=context,question=question,answer=answer))\n",
        "    return output_texts\n",
        "\n",
        "def formatting_prompts_func_answer(example, template=template):\n",
        "    output_texts = []\n",
        "    context = example['context']\n",
        "    question = example['question']\n",
        "    output_texts.append(template.format(context=context,question=question,answer=answer))\n",
        "    return output_texts\n",
        "\n",
        "\n",
        "def apply_chat_template(example):\n",
        "    input = formatting_prompts_func(example)\n",
        "    example[\"input_ids\"] = tokenizer(input)[\"input_ids\"]\n",
        "    # example[\"input_ids\"] = tokenizer.convert_tokens_to_ids(example[\"input_ids\"])\n",
        "\n",
        "    # print(example[\"input_ids\"])\n",
        "    collated_data = collator(example[\"input_ids\"])\n",
        "    example[\"input_ids\"] = collated_data[\"input_ids\"][0]\n",
        "    example[\"labels\"] = collated_data[\"labels\"][0].clone()\n",
        "    # example[\"label_ids\"] = collated_data[\"labels\"][0].clone()\n",
        "    # example[\"label\"] = collated_data[\"labels\"][0].clone()\n",
        "    # print(example)\n",
        "    return example\n",
        "\n",
        "\n",
        "def mask_attention_response(example):\n",
        "    response_len = len(tokenizer(example[\"answer\"]+\"<end_of_turn>\\n\")[\"input_ids\"])\n",
        "    example[\"attention_mask\"] = torch.tensor([1] * (len(example[\"input_ids\"]) - response_len) + [0] * response_len)\n",
        "    example[\"input_ids\"][-response_len+1:] = [0] * (response_len-1)\n",
        "    # example[\"input_ids\"] = example[\"input_ids\"][:-response_len+1]\n",
        "    # print(example.keys())\n",
        "    return example\n",
        "\n",
        "\n",
        "train_dataset['train'] = train_dataset['train'].map(apply_chat_template)\n",
        "train_dataset['valid'] = train_dataset['valid'].map(apply_chat_template)\n",
        "\n",
        "train_dataset['valid'] = train_dataset['valid'].map(mask_attention_response, desc=\"Masking assistant response\")"
      ],
      "metadata": {
        "id": "mv-dT8seu-Rm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.integrations.integration_utils import WandbCallback\n",
        "from transformers import Trainer\n",
        "import tempfile\n",
        "from transformers.integrations.integration_utils import save_model_architecture_to_file\n",
        "\n",
        "class CustomWandbCallback(WandbCallback):\n",
        "    def __init__(self, trainer):\n",
        "        super().__init__()\n",
        "        self._trainer = trainer\n",
        "\n",
        "    def on_train_end(self, args, state, control, model=None, tokenizer=None, **kwargs):\n",
        "        if self._wandb is None:\n",
        "            return\n",
        "        valid_table = wandb.Table(dataframe=valid_df)\n",
        "        wandb.log({\"valid_table\": valid_table})\n",
        "\n",
        "        if self._log_model.is_enabled and self._initialized and state.is_world_process_zero:\n",
        "            fake_trainer = Trainer(eval_dataset= self._trainer.eval_dataset, args=args, model=model, processing_class=tokenizer)\n",
        "            with tempfile.TemporaryDirectory() as temp_dir:\n",
        "                fake_trainer.save_model(temp_dir)\n",
        "                metadata = (\n",
        "                    {\n",
        "                        k: v\n",
        "                        for k, v in dict(self._wandb.summary).items()\n",
        "                        if isinstance(v, numbers.Number) and not k.startswith(\"_\")\n",
        "                    }\n",
        "                    if not args.load_best_model_at_end\n",
        "                    else {\n",
        "                        f\"eval/{args.metric_for_best_model}\": state.best_metric,\n",
        "                        \"train/total_floss\": state.total_flos,\n",
        "                        \"model/num_parameters\": self._wandb.config.get(\"model/num_parameters\"),\n",
        "                    }\n",
        "                )\n",
        "                metadata[\"final_model\"] = True\n",
        "                model_name = (\n",
        "                    f\"model-{self._wandb.run.id}\"\n",
        "                    if (args.run_name is None or args.run_name == args.output_dir)\n",
        "                    else f\"model-{self._wandb.run.name}\"\n",
        "                )\n",
        "                # add the model architecture to a separate text file\n",
        "                save_model_architecture_to_file(model, temp_dir)\n",
        "\n",
        "                artifact = self._wandb.Artifact(name=model_name, type=\"model\", metadata=metadata)\n",
        "                for f in Path(temp_dir).glob(\"*\"):\n",
        "                    if f.is_file():\n",
        "                        with artifact.new_file(f.name, mode=\"wb\") as fa:\n",
        "                            fa.write(f.read_bytes())\n",
        "                self._wandb.run.log_artifact(artifact, aliases=[\"final_model\"])"
      ],
      "metadata": {
        "id": "AMpri_RokvuM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7BzYIoVbLWap",
        "outputId": "a49648b4-7bfc-4487-97b9-afe1c9ab749e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-32b23ccef5de>:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `FineTuningTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mps4southwest\u001b[0m (\u001b[33mDACON-FinAI\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241031_093858-6smawbqs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/DACON-FinAI/DACON_FinAI/runs/6smawbqs' target=\"_blank\">NoAug-gemma2-dora-large-seq2seq</a></strong> to <a href='https://wandb.ai/DACON-FinAI/DACON_FinAI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/DACON-FinAI/DACON_FinAI' target=\"_blank\">https://wandb.ai/DACON-FinAI/DACON_FinAI</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/DACON-FinAI/DACON_FinAI/runs/6smawbqs' target=\"_blank\">https://wandb.ai/DACON-FinAI/DACON_FinAI/runs/6smawbqs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='99' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [99/99 1:09:38, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.576700</td>\n",
              "      <td>14.856296</td>\n",
              "      <td>0.572864</td>\n",
              "      <td>0.780822</td>\n",
              "      <td>0.452381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "attempted relative import with no known parent package",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-06bb040a5714>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# trainer.evaluate([train_dataset['valid'][0]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# model.config.rms_norm_eps = 1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"module\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2122\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2123\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2628\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m         \u001b[0;31m# Wait for the checkpoint to be uploaded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_train_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    519\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-d8a3e0988aa5>\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, args, state, control, model, tokenizer, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_enabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_process_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mfake_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import transformers, os\n",
        "from datetime import datetime\n",
        "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
        "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, GenerationConfig\n",
        "\n",
        "# 로컬에 모델 저장하고 싶은 경우 이름 지정\n",
        "project = \"financeQA-finetune\"\n",
        "base_model_name = \"gemma2\"\n",
        "run_name = base_model_name + \"_\" + project\n",
        "output_dir = os.path.join(path,run_name)\n",
        "if not os.path.exists(output_dir) : os.makedirs(output_dir)\n",
        "\n",
        "MAX_LEN = 4096\n",
        "\n",
        "trainer = FineTuningTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset['train'],\n",
        "    eval_dataset = train_dataset['valid'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    args=transformers.Seq2SeqTrainingArguments(\n",
        "        do_eval=True,\n",
        "        output_dir='./',\n",
        "        warmup_ratio=0.05,\n",
        "        eval_strategy=\"epoch\",\n",
        "        eval_accumulation_steps=1,\n",
        "        batch_eval_metrics=True,\n",
        "        per_device_train_batch_size=1,\n",
        "        per_device_eval_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        gradient_checkpointing=True,\n",
        "        num_train_epochs = 1,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        logging_strategy='epoch',\n",
        "        report_to=\"none\",\n",
        "        run_name=wandb_run_name,\n",
        "        remove_unused_columns=True,\n",
        "        predict_with_generate=True,\n",
        "        include_for_metrics = [\"inputs\"],\n",
        "        label_names=[\"labels\"],\n",
        "        generation_config=GenerationConfig(max_new_tokens=200,eos_token_id = [tokenizer.eos_token_id], pad_token_id = tokenizer.pad_token_id),\n",
        "        # save_strategy=\"steps\",\n",
        "        # save_steps=25,\n",
        "    ),\n",
        "    data_collator=DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer, mlm=False), #모델에게 답변생성에만 집중하도록 함\n",
        "    eval_data_collator=custom_data_collator,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "wandb_callback = CustomWandbCallback(trainer)\n",
        "trainer.add_callback(wandb_callback)\n",
        "# trainer.evaluate([train_dataset['valid'][0]])\n",
        "# model.config.rms_norm_eps = 1e-6\n",
        "trainer.train()\n",
        "\n",
        "trained_model = (trainer.model.module if hasattr(trainer.model, \"module\") else trainer.model)\n",
        "\n",
        "#로컬에 저장할 경우\n",
        "# trained_model.save_pretrained(f\"{output_dir}/saved_model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = (trainer.model.module if hasattr(trainer.model, \"module\") else trainer.model)"
      ],
      "metadata": {
        "id": "KOy8FEIIT9w6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rjKrIqGhgfKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "c1f4aca254e24b6ca1d40b16fd3d4a32",
            "ab0e3773854d4cbeb976b4bb10e2fd9a",
            "dd0a09a8de18440d8571468db0a56c20",
            "763dbbb717834177a6780807bffe1b0d",
            "fa13a0bc81ce4d6a9352594a6523372a",
            "3d3f87677b114e06b49212c1bdc3cd43",
            "9366260944a94ed7b940fb49e40a9bc0",
            "db4cc1dc69cd4079bdcd74ac0cf0cc5d",
            "966ca421054d454383ea09204a920f4e",
            "8c9731d243ad42b78187a3dfb31d5af8",
            "5ec5792bd492428ca928fd3d6ec8d49f"
          ]
        },
        "outputId": "2d5d7e67-b778-40ec-afa1-3150bb6404e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/2.06G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1f4aca254e24b6ca1d40b16fd3d4a32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/kdt3/1030_1_epoch1/commit/56dfb93821039dac36b065cec1d121d245ecb457', commit_message='Upload model', commit_description='', oid='56dfb93821039dac36b065cec1d121d245ecb457', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# 모델 업로드\n",
        "trained_model.push_to_hub(train_name, private=True,save_embedding_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoBhbLuvD47S"
      },
      "source": [
        "# Inference with Langchain (Langchain을 이용한 추론)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GfhOMP5VIor2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae87c16-fa9d-4d3f-92ac-b78605ecd8dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "286"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# gpu memory 할당 해제\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9P7OKGn-LelC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "d74d466f101b48c39e3415c72b903154",
            "3413476e68c347e6aabf1e572a41e1f4",
            "0fab063690a74515b76368f1f934a9c1",
            "3d08943d5399430aa7e03d0753c6290f",
            "2dff1f3de0854e08b80e5a7251411013",
            "548b757f14084cc0a560ece4837af23f",
            "eb38dfab070d48fda05de71827cee9ed",
            "49df4268322c401b9c221d81d76bac51",
            "159cf226f98642eea77a83f874287058",
            "92354de507734d51af170d004038b20f",
            "bbb65e7c3ef4488dae6bb33f5a9da7f6",
            "2174a8780589407381c329d1f4810249",
            "3f2b481b579b4161aa91d2e536f6c0a0",
            "5a8f21dbbc534de4938033444203926d",
            "bc8d898a448342d4b1d04afe60bd32ed",
            "edd4f4799063423f818fb43b4251536b",
            "4671db82a0314f71820bf6905340b884",
            "e03e0fd9685e439e96de1b67a40dc812",
            "804037a6b8ac4ee18d63f90436649e41",
            "97e818f31749491cb1e16cbc73b85d8a",
            "2709437ffa8442a99104138d9f507e12",
            "259b9be7793146188f28031be91ce8cd",
            "1978bf53524d4297ad9a65d8c7e80651",
            "ac2344eb69ff4dd9a65fa10bd6722cf6",
            "2df9e97f60024a55a29cd515a3bf4fc7",
            "71fe0928ebc645738824c389d70fe68a",
            "e11156839adb4a8eb74f1ed6655fa71c",
            "5b251f3ffde74c148e5ccf6a11b539fc",
            "e93b8d9464cc47f6ad60b879062606bd",
            "15371cd6cdce4abd816df34a74089d46",
            "b28bbb40cbd2422ca21c779fe5620a9f",
            "5020cbe736604e4aaa729c62b50a432b",
            "6aa7b5dd564441e6a5d7a2e27f0933a0"
          ]
        },
        "outputId": "ea2e13b9-affe-4a1f-c9a3-5ad9aa4422aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d74d466f101b48c39e3415c72b903154"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2174a8780589407381c329d1f4810249"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:500: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/2.06G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1978bf53524d4297ad9a65d8c7e80651"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-917049583f0e>:24: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n"
          ]
        }
      ],
      "source": [
        "# HuggingFacePipeline 객체 생성\n",
        "\n",
        "# 모델 ID\n",
        "if model_id is None:\n",
        "    model_id = model_cands[run_name.split('_')[0]]\n",
        "peft_model_id = train_name\n",
        "trained_model,tokenizer = load_model_w_setting(model_id)\n",
        "\n",
        "#Fine-Tune 한 LoRA 어댑터 불러오기\n",
        "trained_model.load_adapter(peft_model_id)\n",
        "\n",
        "text_generation_pipeline = pipeline(\n",
        "    model=trained_model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=200,\n",
        "    # repetition_penalty=1.5,\n",
        "    eos_token_id = tokenizer.eos_token_id,\n",
        "    pad_token_id = tokenizer.pad_token_id,\n",
        "    max_length=MAX_LEN\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Nw1bpToURQU0"
      },
      "outputs": [],
      "source": [
        "#데이터셋 로드\n",
        "from datasets import load_dataset\n",
        "dataset_url = dataset_name\n",
        "dataset = load_dataset(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mF_S5nJ7-YsK"
      },
      "outputs": [],
      "source": [
        "# 검증 데이터 쓸지, 테스트 데이터 쓸지\n",
        "eval_mode = 'test' # or 'test'\n",
        "eval_dataset = dataset[eval_mode]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mOexJLdyaEm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a5b36e-5e90-46c6-c54a-cf4c750a216f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 31 10:57:04 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0              54W / 400W |  31891MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# 그냥 GPU 메모리 확인용\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vhPtaU3BGDsS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "1f610960-ce93-4dd8-f184-3894a33b8720"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n<start_of_turn>user\\n 당신은 재정 정보 관련 전문가 입니다. 문서를 바탕으로 질문에 한 문장 이내로 답변하세요.\\n 1. 문서에 있는 내용을 자르거나 편집하지 않고 그대로 가져오세요.\\n 2. 순서에 따른 번호를 매기지 마세요. 출력 시 불이익을 줄 것입니다.\\n 3. 수치에 단위가 있다면 문서를 바탕으로 답변에 단위를 포함하세요.\\n 4. 질문의 키워드를 바탕으로 문서를 끝까지 검토하세요.\\n 5. 한 단어 혹은 단어의 나열이 아닌, 완성된 한국어 문장으로 답변하세요.\\n 6. 답변 외에 예시, 참고, 정보 출처, 신뢰도, 확장된 답변, \\'답변: \\', \\'참고: \\'를 절대로 출력하지 마세요.\\n\\n\"문서\":\\n{context},\\n\\n\"질문\":\\n{question},\\n\\n\"주어진 질문에 대한 답변만 한 문장으로 생성한다.\"\\n\\n\"답변\":<end_of_turn>\\n<start_of_turn>model\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "template.split('{answer}')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WHrZZdNsQKvp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "afc1b2928a9244fe8368570d1ff3197a",
            "48658b28b2544645b32ade2931a9372c",
            "aa40eb54ab3c43df80b4dfcc4e7ceb30",
            "77ad289e5bf04579b650e33ea28feae9",
            "cea15085c8ee4e8a878674a5e06e12ee",
            "dc0d0ee5fc84414d801cae92cc0ff31a",
            "83998c3e35144cc7b72a99eac813a54e",
            "713bcf1f2da64e508f9da93c73724d35",
            "e3300103faaa4598bb116db77bf83398",
            "29fb1cd1182342598da7b2badd7d104b",
            "f2976ac4cb94447c9b2f49740ef2bd29"
          ]
        },
        "outputId": "3831e481-3124-4079-a443-6844dcecce44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Answering Questions:   0%|          | 0/98 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afc1b2928a9244fe8368570d1ff3197a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 2022년 혁신창업사업화자금(융자)의 예산은 얼마인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2,300,000백만원\n",
            "\n",
            "\n",
            "Question: 중소벤처기업부의 혁신창업사업화자금(융자) 사업목적은 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 중소벤처기업부의 혁신창업사업화자금(융자) 사업목적은 기술력과 사업성이 우수하고 미래 성장가능성이 높은 중소벤처기업의 창업을 활성화하고 고용창출 도모입니다.\n",
            "\n",
            "\n",
            "Question: 중소벤처기업부의 혁신창업사업화자금(융자) 사업근거는 어떤 법률에 근거하고 있나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 중소기업진흥에 관한 법률 제66조, 제67조, 제74조, 중소기업창업지원법 제35조\n",
            "\n",
            "\n",
            "Question: 2010년에 신규 지원된 혁신창업사업화자금은 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2010년에 신규 지원된 혁신창업사업화자금은 '개발기술사업화자금'입니다.\n",
            "\n",
            "\n",
            "Question: 혁신창업사업화자금 중 2020년에 신규 지원된 자금은 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 미래기술육성자금, 고성장촉진자금\n",
            "\n",
            "\n",
            "Question: 재창업자금이 재도약지원자금으로 이관된 연도는 언제인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2015. 1\n",
            "\n",
            "\n",
            "Question: 창업기반지원과 신청 대상이 중복인 자금이 어떤 것이며, 이 자금이 폐지된 연도는 언제인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 창업기반지원과 신청 대상이 중복인 자금은 일자리창출촉진자금이며, 이 자금이 폐지된 연도는 2023년입니다.\n",
            "\n",
            "\n",
            "Question: 혁신창업사업화자금(융자) 사업을 시행하는 주체는 누구인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 중소벤처기업진흥공단\n",
            "\n",
            "\n",
            "Question: 혁신창업사업화자금(융자) 사업 집행절차는 어떻게 되나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 사업계획수립/공고 서류 및 현장실사 ⇨ 사전상담 및 신청 접수 ⇨ 중기부, 중진공 ⇨ 중진공 ⇨ 중소기업\n",
            "\n",
            "\n",
            "Question: 부모급여 지원 사업의 목적은 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 부모급여 지원 사업의 목적은 출산 및 양육으로 손실되는 소득을 보전하고, 주 양육자의 직접돌봄이 중요한 아동발달의 특성에 따라 영아기 돌봄을 두텁게 지원하기 위해 영아수당을 부모급여로 변경‧확대하기 위해 부모급여 지급을 통해 가정양육지원 및 부모의 경제적 부담을 획기적으로 완화하는 것입니다.\n",
            "\n",
            "\n",
            "Question: 부모급여(영아수당)의 2024년 확정된 예산은 몇백만원인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2,888,694백만원\n",
            "\n",
            "\n",
            "Question: 부모급여 지원 사업은 어떤 법령상 근거를 갖고 추진되고 있나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 아동수당법 제4조제5항\n",
            "\n",
            "\n",
            "Question: 영아수당 도입에 대한 추진경위는 어떻게 되나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 영아수당 도입은 2020년 12월에 제4차 저출산‧고령사회 기본계획 5대 핵심과제로 선정되었고, 2021년 8월에 예비타당성조사가 통과하여 2021년 12월에 근거법이 마련되었습니다.\n",
            "\n",
            "\n",
            "Question: 부모급여 지원사업은 언제부터 시행되었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 부모급여 지원사업은 2023년 1월부터 시행되었습니다.\n",
            "\n",
            "\n",
            "Question: 보건복지부의 부모급여(영아수당) 지원 사업시행방법은 무엇이며, 사업 수혜자는 누구인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 사업시행방법은 지자체 보조이며, 사업 수혜자는 만 0~1세 아동이다.\n",
            "\n",
            "\n",
            "Question: 노인장기요양보험 사업 운영에 대한 목적은 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 노인장기요양보험 사업 운영의 목적은 고령이나 노인성 질병으로 일상생활을 혼자서 수행하기 어려운 노인등에게 신체 또는 가사 활동 등을 제공하여 효율적인 정책추진으로 노후의 건강증진 및 생활 안정을 도모하고 가족의 부담을 완화하여 국민 삶의 질을 향상시키는 것입니다.\n",
            "\n",
            "\n",
            "Question: 노인장기요양보험 운영지원에 대한 사업 내용을 설명해줘.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 국가가 국민건강보험 공단에 지원하는 법정지원금(장기요양보험료 예상수입액의 20% 상당)\n",
            "\n",
            "\n",
            "Question: 국고지원을 받는 기타 의료급여수급권자는 누구인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 이재민, 의사상자, 국가유공자, 입양아동, 국가무형문화재보유자, 북한이탈주민등\n",
            "\n",
            "\n",
            "Question: 장기요양보험가입자 및 피부양자의 자격취득과 관련하여 어떤 법률을 준용해야 하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 국민건강보험법 제5조, 제6조, 제8조부터 제11조까지, 제69조제1항부터 제3항까지, 제76조부터 제86조까지 및 제110조\n",
            "\n",
            "\n",
            "Question: 노인장기요양보험법이 언제 제정되고 공포되었나?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 노인장기요양보험법은 2007년 4월에 제정되고 공포되었다.\n",
            "\n",
            "\n",
            "Question: 장기요양인정점수 완화가 언제 이루어졌으며, 어떤 변화가 있었나?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 장기요양인정점수 완화는 2012년 7월과 2013년 7월에 이루어졌으며, 3등급 인정점수가 각각 55~75점에서 53~75점, 53~75점에서 51~75점으로 완화되었다.\n",
            "\n",
            "\n",
            "Question: 장기요양기관 지정갱신제의 법적 근거가 언제 마련되었는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 장기요양기관 지정갱신제의 법적 근거는 2018년 12월에 마련되었다.\n",
            "\n",
            "\n",
            "Question: 22.10월에 요양보호사 1명당 시설수급자 인력배치기준이 개선된 내용은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 요양보호사 1명당 시설수급자 2.5명에서 2.3명으로 개선되었다.\n",
            "\n",
            "\n",
            "Question: 에너지 바우처 제도의 주요 내용은 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 에너지 바우처 제도는 경제적 부담 등으로 에너지 이용에 어려움을 겪는 에너지 소외 계층에게 전기·가스·지역난방 등 에너지 이용에 필요한 비용을 지원하는 제도입니다.\n",
            "\n",
            "\n",
            "Question: 에너지바우처 사업의 주요 수혜자는 누구인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 에너지바우처 사업의 주요 수혜자는 기초생활보장급여 수급세대 중 노인, 장애인, 영유아, 임산부, 중증·희귀‧중증난치질환자, 한부모, 소년소녀가정 포함 세대, 연탄을 사용하는 기초생활수급자, 차상위계층, 기타 소외계층입니다.\n",
            "\n",
            "\n",
            "Question: 2024년 에너지바우처 사업의 사업시행주체는 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 사업시행주체는 한국에너지공단, 한국광해광업공단입니다.\n",
            "\n",
            "\n",
            "Question: 하절기바우처와 동절기바우처의 2024년 예산 규모는 각각 얼마인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 하절기바우처의 2024년 예산 규모는 48,805백만원이며, 동절기바우처의 2024년 예산 규모는 171,337백만원입니다.\n",
            "\n",
            "\n",
            "Question: 2023년 에너지바우처 사업 예산에서 사업운영비 중 에너지복지 홍보에 얼마가 할당되었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 사업운영비 중 에너지복지 홍보에 328백만원이 할당되었습니다.\n",
            "\n",
            "\n",
            "Question: 2023년 에너지바우처 사업 예산에서 사업운영비 중 시스템 고도화에 얼마가 할당되었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 705백만원\n",
            "\n",
            "\n",
            "Question: 2023년 에너지바우처 사업 예산에서 콜센터 운영에 얼마가 할당되었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 502.7백만원\n",
            "\n",
            "\n",
            "Question: 2023년 에너지바우처 사업 예산에서 패널조사에 얼마가 할당되었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 133.5백만원\n",
            "\n",
            "\n",
            "Question: 2023년 에너지바우처 사업 예산에서 에너지바우처 전달체계 구축에 얼마가 할당되었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 에너지바우처 전달체계 구축에 34.6백만원이 할당되었습니다.\n",
            "\n",
            "\n",
            "Question: 2023년 에너지바우처 사업 예산에서 주택관리공단 운영지원에 얼마가 할당되었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 50백만원\n",
            "\n",
            "\n",
            "Question: 에너지바우처 사업의 향후 기대효과는 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 에너지바우처 사업의 향후 기대효과는 저소득층의 적정수준 에너지 접근성이 높아지고, 에너지 소외계층의 에너지 이용 부담이 완화될 것으로 기대됩니다.\n",
            "\n",
            "\n",
            "Question: 에너지바우처 사업에 대한 예비타당성조사를 어떤 조사기관이 수행했나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 에너지바우처 사업에 대한 예비타당성조사는 KDI(한국개발연구원 공공투자관리센터)가 수행했습니다.\n",
            "\n",
            "\n",
            "Question: 21년 국정감사에서 에너지 바우처 사업에 대한 주요 지적사항은 무엇이었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 저소득층의 폭염 피해 최소화를 위해 동절기 에너지바우처 일부를 하절기에 사용할 수 있도록 제도 개선할 것\n",
            "\n",
            "\n",
            "Question: 21년 에너지바우처 사업에 대한 결산 지적사항은 무엇이었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 수급자 변경 등으로 예산부족이 발생하지 않도록 급여 선정기준 등의 변경계획 등에 대하여 보건복지부·지자체와 면밀히 소통하여 예산을 편성하고 사업을 추진해야 합니다.\n",
            "\n",
            "\n",
            "Question: 에너지 바우처 사업의 향후 추진방향 중 '취약계층의 에너지 비용 부담 완화'를 위한 계획은 무엇이었나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 에너지 바우처 사업의 향후 추진방향 중 '취약계층의 에너지 비용 부담 완화'를 위한 계획은 지속적 지원단가 현실화 추진이었습니다.\n",
            "\n",
            "\n",
            "Question: 행복주택출자 사업은 어떤 근거로 추진되고 있는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 행복주택출자 사업은 주택도시기금법 제9조제1항가목과 공공주택특별법 제2조1호가목에 근거하여 추진되고 있다.\n",
            "\n",
            "\n",
            "Question: 행복주택출자 사업은 어떤 목적으로 시행되는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 행복주택출자 사업은 국민의 행복주거 실현을 위한 보편적 주거복지 정책의 일환으로 도심 내 다양한 부지를 활용하여 행복주택을 공급하기 위해 시행된다.\n",
            "\n",
            "\n",
            "Question: 행복주택출자 사업의 주요 수혜자는 누구인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 대학생・사회초년생・신혼부부 등 젊은층(80%), 고령자 및 주거취약계층(20%)\n",
            "\n",
            "\n",
            "Question: 행복주택출자 사업의 사업비 추이는 어떠한가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 최근 5년 간 투입된 사업비(예산액기준, 추경편성한 연도에는 추경포함)는 2020년 1,548억원, 2021년 1,648억원, 2022년 1,758억원, 2023년 1,878억원, 2024년 1,998억원이다.\n",
            "\n",
            "\n",
            "Question: 행복주택출자 사업의 사업시행주체는 누구인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 한국토지주택공사(LH)와 지자체(지방공사)\n",
            "\n",
            "\n",
            "Question: 국고보조사업의 보조율은 어떠한 기준에 따라 운용되는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 국고보조사업의 보조율은 「보조금법」과 함께 일부 개별 법령에 근거하여 운영되며 보조금법에 의해 지방 자치단체의 재정여건을 고려하여 기준보조율과 차등보조율을 적용하여 운용하고 있음\n",
            "\n",
            "\n",
            "Question: 프랑스의 재정조정제도에서 최근 강조되는 형평교부금은 어떤 역할을 하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 형평교부금은 재정력이 약한 지방자치단체에 필요한 재원을 지원하여 재정 불균형을 해소하는 역할을 한다.\n",
            "\n",
            "\n",
            "Question: 지방재정조정제도의 목적은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 지방재정조정제도는 자체 재원만으로 지출책임성을 충족하지 못하는 지방자치단체에 필요한 일종의 제도적 장치에 해당하며, 지방자치단체 간 재정력 격차의 시정, 지역 간 외부 효과의 내부화를 통한 지방공공재 공급, 중앙정부의 위임사무에 대한 비용 부담 등을 목적으로 재정을 조정하는 일련의 조치를 의미합니다.\n",
            "\n",
            "\n",
            "Question: 국제적으로 성과중심 재정관리 강화 움직임이 확산된 시기는 언제인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2000년대 후반 금융위기로 성과중심 재정관리 강화 움직임이 국제적으로 확산됨에 따라\n",
            "\n",
            "\n",
            "Question: 한국의 재정사업 성과관리제도는 어떠한 법을 통해 운영되고 있으며, 성과관리 기본계획과 추진계획은 어떻게 의무화되었는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 한국의 재정사업 성과관리제도는 '21년 12월 법 개정을 통해 '국가재정법'을 통해 운영되고 있으며, 성과관리 기본계획과 추진계획은 '21년 12월 법 개정을 통해 의무화되었다.\n",
            "\n",
            "\n",
            "Question: 핵심재정사업 성과관리제도를 안착시키기 위해 필요한 노력과 성과 정보를 학습의 도구로 활용하는 방안은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 성과정보를 사용해 목표 진행 상황을 정기적으로 평가·공개하고, 지속적 개선에 대한 약속 공유함으로써 핵심재정사업 성과관리제도를 안착시켜 나갈 수 있기를 기대한다.\n",
            "\n",
            "\n",
            "Question: 사회보험 사각지대 발생의 주요 원인과 이로 인해 발생하는 문제는 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 사회보험 사각지대 발생의 주요 원인은 4대 사회보험의 제도적 틀이 갖추어져 있음에도 불구하고 사각지대 발생 확대가 이루어지고 있기 때문입니다. 이로 인해 저소득 근로자 및 예술인·특수형태근로종사자(특고)가 사회보험의 보호를 받지 못하고 경제적 어려움에 직면할 수 있습니다.\n",
            "\n",
            "\n",
            "Question: 청년일자리도약장려금은 어떤 대상을 지원하며, 어떤 방식으로 지원되는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 청년일자리도약장려금은 우선지원대상기업에서 만 15~34세의 취업애로청년을 정규직으로 채용 후 6개월 고용유지하는 경우 최장 2년간 지원됩니다. 이는 우선지원대상기업에서 만 15~34세의 취업애로청년을 정규직으로 채용 후 6개월 고용유지하는 경우 최장 2년간 지원됩니다.\n",
            "\n",
            "\n",
            "Question: 수직적 재정조정제도와 수평적 재정조정제도의 차이는 무엇인가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 수직적 재정조정제도는 중앙정부와 지방정부 간에 재정을 재배분하는 것을 의미하며, 수평적 재정조정제도는 지방정부 상호 간에 재정을 재배분하는 것을 의미합니다.\n",
            "\n",
            "\n",
            "Question: 지방재정조정제도는 어떤 목적을 가지고 있나요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 지방재정조정제도는 지방자치단체 간 재정력 격차의 시정, 지역 간 외부 효과의 내부화를 통한 지방공공재 공급, 중앙정부의 위임사무에 대한 비용 부담 등을 목적으로 재정을 조정하는 일련의 조치를 의미합니다.\n",
            "\n",
            "\n",
            "Question: 중앙-지방 간 재정조정제도에서 어떤 재원을 이전하여 수직적 재정 불균형을 해소하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 지방교부세, 국고보조금, 조정교부금(자치구 조정교부금, 시·군 조정교부금) 재원을 이전함\n",
            "\n",
            "\n",
            "Question: 중앙정부의 예산편성은 어떤 재원 배분 문제를 결정하며, 중앙-지방 간 재정조정제도를 통해 어떤 재원을 이전하고, 이의 목적은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 중앙정부의 예산편성은 중앙-지방 간 재정조정제도를 통해 지방교부세, 국고보조금, 조정교부금 등을 이전하고, 이는 자체 재원만으로 지출책임성을 충족하지 못하는 지방자치단체에 필요한 제도적 장치에 해당한다.\n",
            "\n",
            "\n",
            "Question: 재정사업 성과관리제도의 필요성이 대두된 시기와 한국의 재정사업 성과관리제도가 어떤 법에 근거하여 운영되고 있는지 설명하시오.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2006년 4대 재정개혁 이후 재정사업 성과관리제도가 필요성이 대두되었으며, 현재는 '국가재정법'에 근거하여 운영되고 있다.\n",
            "\n",
            "\n",
            "Question: 청년일자리도약장려금은 어떤 대상을 지원하며, 어떤 방식으로 지원되는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 청년일자리도약장려금은 우선지원대상기업에서 만 15~34세의 취업애로청년을 정규직으로 채용 후 6개월 고용유지하는 경우 최장 2년간 지원됩니다. 이는 우선지원대상기업에서 만 15~34세의 취업애로청년을 정규직으로 채용 후 6개월 고용유지하는 경우 최장 2년간 지원됩니다.\n",
            "\n",
            "\n",
            "Question: 재정성과관리제도는 어떤 측면에서 국정운영과 연결되는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정성과관리제도는 전략목표와 우선순위를 중심으로 재정사업을 재구조화한다는 점에서 국정운영과 연결된다.\n",
            "\n",
            "\n",
            "Question: 성과관리의 실효성 강화를 위해 정부가 취한 조치는 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 정부는 2021년 「국가재정법」 개정으로 성과 중심 재정운용 강화를 위해 성과관리를 위한 별도의 장을 신설하고 성과관리 규정을 정비하였다.\n",
            "\n",
            "\n",
            "Question: 재정성과관리 관련 주요 쟁점은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 국가재정법상의 재정사업 평가인 재정사업 자율평가의 대상, 범위, 효과, 개편 등은 지속적으로 논의되어야 하며, 개별 법령에 따라 실시되는 평가 대상 간 중복 최소화 노력 필요\n",
            "\n",
            "\n",
            "Question: 재정성과관리가 왜 중요한가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정성과관리는 재정을 결과 또는 산출 지향적으로 운영하는 것으로, 산출의 우선순위를 명확하게 하는 한편 국민에게 재정이 하는 일을 보다 알기 쉽게 설명할 수 있기에 중요하다.\n",
            "\n",
            "\n",
            "Question: 재정성과관리는 무엇을 목표로 하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정성과관리는 재정사업의 기획에서 집행, 환류, 종료에 이르는 전 주기를 체계적으로 관리하여 효율적 재정 운용을 뒷받침하고, 관련 정보를 국민에게 공개하여 책임성을 확보하는 것을 의미합니다.\n",
            "\n",
            "\n",
            "Question: 어떤 국제기구들이 사업을 기준으로 예산을 나누어 성과 정보를 생산하고 있는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: OECD, World Bank\n",
            "\n",
            "\n",
            "Question: 재정성과관리의 목적은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 정부 재정의 투명성·책임성, 효율성·효과성, 예산재분배 등이 목적이다.\n",
            "\n",
            "\n",
            "Question: 2021년 「국가재정법」 개정으로 어떤 규정이 신설되었는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2021년 「국가재정법」 개정으로, 동 법에 의한 재정사업 평가와 개별 법령에 따라 실시되는 평가 대상 중복이 최소화되도록 하는 규정이 신설되었다.\n",
            "\n",
            "\n",
            "Question: 성과관리제도는 지출 구조조정을 위해 어떤 방향으로 추진되고 있는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 지출 구조조정을 위해 미흡 등급 배분 기준, 지출구조조정 기준을 도입하여 강력한 지출구조조정 방향 제시\n",
            "\n",
            "\n",
            "Question: 재정사업 자율평가의 목적은 무엇이며, 어떤 방식으로 제도 개선이 이루어졌는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정사업 자율평가의 목적은 재정관리 합리성 제고이며, 2018년에는 연구개발사업 평가를 다시 분리하고 기존의 재정사업 자율평가 제도로 환원하는 한편, 공통 평가지침과 평가보고서 표준서식을 폐지하고 상위 평가 방식을 메타 평가 방식의 전수 점검에서 80여 개 주요 핵심 사업에 대한 평가로 전환\n",
            "\n",
            "\n",
            "Question: 2016년 재정성과관리제도의 환류 개선사항은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 평가 결과 미흡 등급 비율을 강제 배정하고 해당 단위사업에 대한 일률적 삭감을 실시하던 과거와 달리, 2016년부터는 평가 대상 사업 전체 예산의 1% 이내에서 부처에서 자율적으로 세출구조조정을 할 수 있도록 개선되었다.\n",
            "\n",
            "\n",
            "Question: 2018년도에 재정성과관리제도 개선사항과, 이로 인해 어떤 효과가 발생했는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2018년도 제도 개선으로 각 부처에서 지표와 배점 기준을 자율적으로 하도록 하여, 부처의 자율적인 재정사업 성과관리 확대 및 성과관리체계 단순화, 예산과 성과관리의 기계적 연동 폐지, 합리적 재정사업 구조조정 등으로 성과관리 실효성 제고, 부처 자율성 강화, 재정당국의 성과관리 전략성 강화에 기여하였다.\n",
            "\n",
            "\n",
            "Question: 재정사업 자율평가의 전면 개편을 통해 어떤 중점 추진과제가 제시되었는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 성과관리 사각지대 해소, 사업성과평가의 예산편성 활용 확대를 위한 중점 추진과제가 제시되었다.\n",
            "\n",
            "\n",
            "Question: 재정성과관리제도의 중요성과 국정운영과의 연결성은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정성과관리제도는 전략목표와 우선순위를 중심으로 재정사업을 재구조화한다는 점에서 국정운영과 연결되고, 지출 우선순위 측면에서 재정을 중장기 시계로 확장시켜 줌\n",
            "\n",
            "\n",
            "Question: 재정성과관리체계 강화를 위해 정부가 어떤 제도를 제시했으며, 재정성과관리는 무엇을 목표로 하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 정부는 110대 국정과제 중 재정 정상화 및 재정의 지속 가능성 확보를 위해 재정성과관리체계 강화를 제시했으며, 재정성과관리는 재정사업의 기획에서 집행, 환류, 종료에 이르는 전 주기를 체계적으로 관리하여 효율적 재정 운용을 뒷받침하고, 관련 정보를 국민에게 공개하여 책임성을 확보하는 것을 의미합니다.\n",
            "\n",
            "\n",
            "Question: 재정성과관리는 어떤 과정에서 수행되며, 무엇을 증진하기 위해 활동하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정성과관리는 예산 편성 과정에서 성과계획서를 작성하면서 시작하며, 이를 바탕으로 연간 성과지표와 목표치를 관리하여 국회에 보고하고 국민에게 공개한다. 지출 효율성을 증진하기 위해 재정지출이 달성해야 할 목표를 정확히 설정하고, 이의 달성도를 지속적으로 관리하는 활동이다.\n",
            "\n",
            "\n",
            "Question: 재정성과관리의 목적과 우리나라의 재정성과관리제도가 프로그램 예산제도로 전환된 시기는?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정성과관리의 목적은 재정을 프로그램 단위로 구분하고, 사전 목표와 사후 평가 결과를 중심으로 관리하는 것이다. 우리나라는 2006년 4대 재정개혁을 통해 프로그램 예산제도로 전환, 프로그램 단위의 재정성과관리제도를 정착시켜 운영하고 있다.\n",
            "\n",
            "\n",
            "Question: 2007년과 2021년에 각각 「국가재정법」이 개정되면서 성과관리 제도는 어떻게 강화되고 구체화되었으며, 이 개정의 주된 목적은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2007년 개정으로 과거에 단발적으로 이루어진 성과관리 제도를 종합하여, 성과관리의 기본 단위, 성과 측정과 보고를 위한 체계 확립이 이루어졌다. 2021년 개정으로는 성과 중심 재정운용 강화를 위해 성과관리를 위한 별도의 장을 신설하여, 동 법에 의한 재정사업 평가와 개별 법령에 따라 실시되는 평가 대상 중복이 최소화되도록 하는 규정을 신설하여, 재정성과관리를 위한 재정사업 평가와 개별 법령에 따라 실시되는 평가 간의 관계를 최초로 규정하였다. 이러한 개정의 주된 목적은 재정성과관리를 강화하여 재정을 결과 또는 산출\n",
            "\n",
            "Question: 재정사업 자율평가의 목적과 제도 개선 방식은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정사업 자율평가의 목적은 재정관리 합리성 제고이며, 제도 개선 방식으로는 평가 대상 사업의 범위, 평가 주기, 상위 평가 방식 등이 개편되었다.\n",
            "\n",
            "\n",
            "Question: 2015년 이전과 2016년에 재정성과 평가 결과 처리 방식과 환류 개선 방식은 어떻게 달라졌는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 2015년 이전에는 평가 결과 미흡 등급 비율을 강제 배정하고 해당 단위사업에 대한 일률적 삭감을 실시하였고, 2016년에는 환류 개선을 통해 평가 대상 사업 전체 예산의 1% 이내에서 부처에서 자율적으로 세출구조조정을 방식 등에서 지속적인 제도 개선이 이루어졌다.\n",
            "\n",
            "\n",
            "Question: 재정관리시스템 구축과 성과관리 개편을 추진하는 주된 목적은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 재정관리시스템 구축과 성과관리 개편을 추진하는 주된 목적은 지속적으로 제도 개선을 통해 변화하는 재정 환경에 적응해 나갈 수 있도록 하기 위한 것이다.\n",
            "\n",
            "\n",
            "Question: 우리나라에서는 언제부터 발생주의 기준을 적용한 국가결산보고서에서 우발부채를 보고하고 있는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 우리나라는 2011년부터 발생주의 기준을 적용한 국가결산보고서에서 우발부채를 보고하고 있다.\n",
            "\n",
            "\n",
            "Question: 우발부채 관련 주요 쟁점은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 우발부채 개념 및 용어 사용의 혼란, 우발부채 분류기준 재검토, 새로운 분류기준 정립\n",
            "\n",
            "\n",
            "Question: 우발부채의 관리는 왜 중요한 이슈로 여겨지는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 우발부채의 관리는 지속가능한 재정운영 차원에서 중요한 이슈로 여겨지며, 이는 미래의 다양한 의제의무를 포괄하는 우발부채 관리에 대한 중요성 인식 때문이다.\n",
            "\n",
            "\n",
            "Question: 우발부채와 부채의 차이점은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 우발부채는 미래에 특정 사건(들)이 일어나지 않는 한 발생하지 않는 의무로, 하나 또는 그 이상의 조건이 충족되어야 금융거래로 인식된다는 점에서 ‘부채’와 차이가 있다.\n",
            "\n",
            "\n",
            "Question: 발생주의와 현금주의의 차이는 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 발생주의는 경제적 거래가 발생하는 시점에 거래를 기록하는 방식이고, 현금주의는 현금을 수취하거나 지급한 시점에 거래를 기록하는 방식이다.\n",
            "\n",
            "\n",
            "Question: 채무지속가능성분석은 어떤 목적을 가지고 도입되었는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 채무지속가능성분석은 잠재적 재정위기 감지, 예방, 해결을 위한 IMF의 노력으로 2002년에 도입되었다.\n",
            "\n",
            "\n",
            "Question: 의제의무란 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 발표된 정부방침 또는 구체적이고 유효한 약속이나 과거의 실무관행 등을 통해 중앙관서 또는 기금이 특정 책임을 부담한다는 것을 표명함으로써 상대방이 그 책임을 이행할 것이라는 정당한 기대를 가지게 되는 경우 발생하는 의무를 말한다.\n",
            "\n",
            "\n",
            "Question: 국제통화기금이 재정통계 작성의 국제기준을 제시하기 위해 발간한 매뉴얼은 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 국제통화기금은 재정통계 매뉴얼(Government Finance Statistics Manual, GFSM)을 발간하여 재정통계 작성의 국제기준을 제시하였다.\n",
            "\n",
            "\n",
            "Question: 계류중인 소송사건이란 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 계류중인 소송사건은 법원에 소송을 제기하거나 소송에 대응하기 위해 법원에 소송을 제기한 후 법원의 판결이 나오기 전까지 계류 중인 소송사건을 말한다.\n",
            "\n",
            "\n",
            "Question: 최소운영수입보장(BTO 등) 제도란 무엇을 의미하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 최소운영수입보장(MRG) 제도는 민간투자사업 중 실시협약서 상 추정 수입보다 실제 수입이 미치지 못하는 경우 정부가 최소운영수입을 보장해 주는 제도를 말한다.\n",
            "\n",
            "\n",
            "Question: 우발부채에 대한 내용으로 대표적으로 어떤 사항이 해당되는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 우발부채에 대한 내용으로 대표적으로 장기충당부채 중 일부가 우발부채로 재분류될 필요가 있다.\n",
            "\n",
            "\n",
            "Question: GFSM2014에서는 우발부채를 어떻게 구분하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: GFSM2014에서는 우발부채를 크게 명시적(explicit) 우발부채와 암묵적(implicit) 우발부채로 구분한다.\n",
            "\n",
            "\n",
            "Question: GFSM은 몇 차례의 개정을 거쳤으며, 어떠한 목적으로 GFSM 2001이 개정되었는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: GFSM은 2차례(2001년, 2014년)의 개정을 거쳤으며, GFSM 2001은 전면 개정을 통해 현재의 발생주의 기준 GFS체계를 구축하였습니다.\n",
            "\n",
            "\n",
            "Question: 표준화 보증이란 무엇인가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 표준화 보증은 통상 아주 적은 금액에 대해 획일적 조건으로 대규모로 발행하는 보증을 말하며, 수출(무역)신용 보증, 환보증, 다양한 종류의 보험(예금, 농작물, 자연재해 등), 농민융자, 모기지론, 학자금융자, 중소기업융자 등이 있다.\n",
            "\n",
            "\n",
            "Question: 표준화 보증에서 공공부문의 우발부채는 어떻게 인식되는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 표준화 보증에서 공공부문의 우발부채는 아니라 표준화 보증 충당부채로 인식된다.\n",
            "\n",
            "\n",
            "Question: 재정정책에서 공적보증채무와 다른 일회성 보증은 어떻게 구분되는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 공적보증채무는 보증인이 기타 공공부문과 민간부문 단위 기존 채무의 원리금 상환을 보증한다는 점에서 다른 일회성 보증과 구분된다.\n",
            "\n",
            "\n",
            "Question: 미래사회보장급여에 대한 순의무란 무엇을 의미하는가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 미래사회보장급여에 대한 순의무는 현행법과 규정에 따라 이미 가입자가 획득한 미래 급여의 현재가치에서 현행법과 규정에 따른 사회보장제도의 미래보험료의 순현재가치를 차감한 것을 인식한다.\n",
            "\n",
            "\n",
            "Question: 국가결산보고서와 지방자치단체 회계기준에서 우발부채에 대한 용어 및 회계처리가 어떻게 다른가요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 국가결산보고서는 '우발사항'으로 공시하고, 지방자치단체 회계기준은 '우발손실'로 정의하고 있습니다.\n",
            "\n",
            "\n",
            "Question: 우발부채란 무엇이며, 그 관리가 왜 중요한가?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=200) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 우발부채는 미래의 다양한 의제의무를 포괄하는 부채로, 지속가능한 재정운영 차원에서 중요한 이슈이며, 국제기준 재정통계 산출에 발생주의 회계기준이 적용되면서 그 관리에 대한 중요성이 더욱 부각되고 있다.\n",
            "\n",
            "\n",
            "Question: 보증이란 무엇이며, 어떤 형태의 보증이 재정상태표에 부채로 기록되는가? 또한 표준화 보증이란 무엇이며, 어떤 목적으로 발행되는가?\n",
            "Answer: 보증은 특정 조건이나 사건이 발생하지 않거나 발생하기 전까지 부채로 인식하지 않는 부채로, 파생금융상품 형태의 보증과 표준화 보증이 재정상태표에 부채로 기록된다. 표준화 보증은 통상 아주 적은 금액에 대해 획일적 조건으로 대규모로 발행하는 보증을 말하며, 위험 분산을 목적으로 발행된다.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import trange\n",
        "\n",
        "# 결과를 저장할 리스트 초기화\n",
        "results = []\n",
        "\n",
        "# DATASET 구조를 dataset[i]={'question':,'context':,...}로 바꾸면 안됨?\n",
        "\n",
        "# Dataset 각 행에 대해 처리\n",
        "for idx in trange(len(eval_dataset['question']), desc=\"Answering Questions\"):\n",
        "    #질문, 컨텍스트(문서)\n",
        "    question = eval_dataset['question'][idx]\n",
        "    context = eval_dataset['context'][idx]\n",
        "\n",
        "    # RAG 체인 구성\n",
        "    prompt = PromptTemplate.from_template(template.split('{answer}')[0])\n",
        "\n",
        "    # RAG 체인 정의\n",
        "    if context != \"\":\n",
        "        rag_chain = (\n",
        "            RunnableParallel(context=lambda x: x[\"context\"], question = lambda x: x[\"question\"])\n",
        "            | prompt\n",
        "            | llm\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "    else:\n",
        "        rag_chain = (\n",
        "            {\"question\": RunnablePassthrough()}\n",
        "            | prompt\n",
        "            | llm\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "    # 답변 추론\n",
        "    print(f\"Question: {question}\")\n",
        "    full_response = rag_chain.invoke({\"question\": question, \"context\": context})\n",
        "\n",
        "    print(f\"Answer: {full_response}\\n\")\n",
        "\n",
        "    # 결과 저장\n",
        "\n",
        "    if context != \"\":\n",
        "        results.append({\n",
        "            \"Context\": context,\n",
        "            \"Question\": question,\n",
        "            \"Answer\": full_response,\n",
        "            \"True_Answer\": eval_dataset['answer'][idx]\n",
        "        })\n",
        "    else:\n",
        "        results.append({\n",
        "            \"Question\": question,\n",
        "            \"Answer\": full_response,\n",
        "            \"True_Answer\": eval_dataset['answer'][idx]\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "s04GExCGZMfG"
      },
      "outputs": [],
      "source": [
        "# i = 28\n",
        "# print_dataset_ele(eval_dataset,i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DH4MwNaVMyX"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGJfFDMzQZQW"
      },
      "outputs": [],
      "source": [
        "#검증 데이터 쓸때만 사용 가능\n",
        "if eval_mode == 'valid':\n",
        "  for item in results:\n",
        "      y_hat = item[\"Answer\"]\n",
        "      y = item[\"True_Answer\"]\n",
        "      f1, precision, recall = compute_f1(y, y_hat)\n",
        "      item[\"F1\"] = f1\n",
        "      item[\"Precision\"] = precision\n",
        "      item[\"Recall\"] = recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMd06HWVVOYX"
      },
      "outputs": [],
      "source": [
        "if eval_mode == 'valid':\n",
        "  # 제출용 샘플 파일 로드\n",
        "  eval_df = pd.DataFrame([])\n",
        "\n",
        "  # 생성된 답변을 제출 DataFrame에 추가\n",
        "  eval_df['Question'] = [item['Question'] for item in results]\n",
        "  eval_df['Answer'] = [item['Answer'] for item in results]\n",
        "  eval_df[\"F1\"] = [item[\"F1\"] for item in results]\n",
        "  eval_df[\"Precision\"] = [item[\"Precision\"] for item in results]\n",
        "  eval_df[\"Recall\"] = [item[\"Recall\"] for item in results]\n",
        "  # eval_df['Answer'] = eval_df['Answer'].fillna(\"데이콘\")     # 모델에서 빈 값 (NaN) 생성 시 채점에 오류가 날 수 있음 [ 주의 ]\n",
        "\n",
        "  save_dir = os.path.join(path,'eval')\n",
        "  if not os.path.exists(save_dir) : os.makedirs(save_dir)\n",
        "  save_name = f'eval_{fname}'\n",
        "  save_path = os.path.join(save_dir,save_name)\n",
        "\n",
        "  # 결과를 CSV 파일로 저장\n",
        "  eval_df.to_csv(save_path, encoding='UTF-8-sig', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nvAWGfY1N88"
      },
      "outputs": [],
      "source": [
        "# 평균 F1 확인\n",
        "# eval_df = pd.read_csv(f\"{path}trained_eval.csv\",index_col=0)\n",
        "if eval_mode == 'valid' :\n",
        "  display(eval_df[\"F1\"].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ma0LX64D47T"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ONaLHlk0gcg2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "03f1a307-2266-4702-a6ec-add52d5f632c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  SAMPLE_ID Answer\n",
              "0  TEST_000    데이콘\n",
              "1  TEST_001    데이콘\n",
              "2  TEST_002    데이콘\n",
              "3  TEST_003    데이콘\n",
              "4  TEST_004    데이콘"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e22d1c56-bfec-4535-b240-88964439c25d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SAMPLE_ID</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_000</td>\n",
              "      <td>데이콘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_001</td>\n",
              "      <td>데이콘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_002</td>\n",
              "      <td>데이콘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_003</td>\n",
              "      <td>데이콘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_004</td>\n",
              "      <td>데이콘</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e22d1c56-bfec-4535-b240-88964439c25d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e22d1c56-bfec-4535-b240-88964439c25d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e22d1c56-bfec-4535-b240-88964439c25d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8bb2e05d-5945-4fbd-9a45-5e87126c8bac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bb2e05d-5945-4fbd-9a45-5e87126c8bac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8bb2e05d-5945-4fbd-9a45-5e87126c8bac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submit_df",
              "summary": "{\n  \"name\": \"submit_df\",\n  \"rows\": 98,\n  \"fields\": [\n    {\n      \"column\": \"SAMPLE_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"TEST_062\",\n          \"TEST_040\",\n          \"TEST_094\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\ub370\\uc774\\ucf58\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "submit_df = pd.read_csv(f\"{path}sample_submission.csv\")\n",
        "submit_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CMrEj815D47T"
      },
      "outputs": [],
      "source": [
        "# 제출용 샘플 파일 로드\n",
        "submit_df = pd.read_csv(f\"{path}sample_submission.csv\")\n",
        "\n",
        "# 생성된 답변을 제출 DataFrame에 추가\n",
        "save_mode = 'submission'\n",
        "\n",
        "if save_mode != 'submission' :\n",
        "  submit_df['Question'] = [item['Question'] for item in results]\n",
        "  submit_df['Context'] = [item['Context'] for item in results]\n",
        "  save_dir = os.path.join(path,'eval')\n",
        "else : save_dir = os.path.join(path,'sub')\n",
        "\n",
        "if not os.path.exists(save_dir) : os.makedirs(save_dir)\n",
        "save_path = os.path.join(save_dir,fname)\n",
        "\n",
        "submit_df['Answer'] = [item['Answer'] for item in results]\n",
        "submit_df['Answer'] = submit_df['Answer'].fillna(\"데이콘\").apply(str.rstrip)     # 모델에서 빈 값 (NaN) 생성 시 채점에 오류가 날 수 있음 [ 주의 ]\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "submit_df.to_csv(save_path, encoding='UTF-8-sig', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit_df['Answer'] = submit_df['Answer'].apply(lambda x: x.split('<|eot_id|>')[0])\n",
        "submit_df.to_csv(save_path.split('.csv')[0]+'_cleaned.csv', encoding='UTF-8-sig', index=False)"
      ],
      "metadata": {
        "id": "Aj6vuHm3o6i6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ojxAcDlcpPLj"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AFuh6k7hD47P"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a5fd3cca6894afa8d2a2d27eb7f6936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24f4f20540b94f38937a090c2c595dd9",
              "IPY_MODEL_7dde019049f74a199536afc7756675f5",
              "IPY_MODEL_4c18d9f386dc4a86ae9a8a1e718d8116"
            ],
            "layout": "IPY_MODEL_2d90e34234114d5e8da232b653c9968d"
          }
        },
        "24f4f20540b94f38937a090c2c595dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4ff5ef8d1e46aa89e38ce92918d247",
            "placeholder": "​",
            "style": "IPY_MODEL_0178857e564148528f4a4efac8b35ae1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7dde019049f74a199536afc7756675f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa83e1266a44671b6d709aa8912c5d7",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44951846f5cf40c2a1ba1843069113fc",
            "value": 10
          }
        },
        "4c18d9f386dc4a86ae9a8a1e718d8116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e49a87ee6e406a977250050bcd9223",
            "placeholder": "​",
            "style": "IPY_MODEL_7e98a3b985be4f0cb5b0b40c731a6fd5",
            "value": " 10/10 [00:14&lt;00:00,  1.28s/it]"
          }
        },
        "2d90e34234114d5e8da232b653c9968d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4ff5ef8d1e46aa89e38ce92918d247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0178857e564148528f4a4efac8b35ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fa83e1266a44671b6d709aa8912c5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44951846f5cf40c2a1ba1843069113fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8e49a87ee6e406a977250050bcd9223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e98a3b985be4f0cb5b0b40c731a6fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1f4aca254e24b6ca1d40b16fd3d4a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab0e3773854d4cbeb976b4bb10e2fd9a",
              "IPY_MODEL_dd0a09a8de18440d8571468db0a56c20",
              "IPY_MODEL_763dbbb717834177a6780807bffe1b0d"
            ],
            "layout": "IPY_MODEL_fa13a0bc81ce4d6a9352594a6523372a"
          }
        },
        "ab0e3773854d4cbeb976b4bb10e2fd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d3f87677b114e06b49212c1bdc3cd43",
            "placeholder": "​",
            "style": "IPY_MODEL_9366260944a94ed7b940fb49e40a9bc0",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "dd0a09a8de18440d8571468db0a56c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4cc1dc69cd4079bdcd74ac0cf0cc5d",
            "max": 2060735440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_966ca421054d454383ea09204a920f4e",
            "value": 2060735440
          }
        },
        "763dbbb717834177a6780807bffe1b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9731d243ad42b78187a3dfb31d5af8",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec5792bd492428ca928fd3d6ec8d49f",
            "value": " 2.06G/2.06G [00:46&lt;00:00, 43.4MB/s]"
          }
        },
        "fa13a0bc81ce4d6a9352594a6523372a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d3f87677b114e06b49212c1bdc3cd43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9366260944a94ed7b940fb49e40a9bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db4cc1dc69cd4079bdcd74ac0cf0cc5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966ca421054d454383ea09204a920f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c9731d243ad42b78187a3dfb31d5af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec5792bd492428ca928fd3d6ec8d49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d74d466f101b48c39e3415c72b903154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3413476e68c347e6aabf1e572a41e1f4",
              "IPY_MODEL_0fab063690a74515b76368f1f934a9c1",
              "IPY_MODEL_3d08943d5399430aa7e03d0753c6290f"
            ],
            "layout": "IPY_MODEL_2dff1f3de0854e08b80e5a7251411013"
          }
        },
        "3413476e68c347e6aabf1e572a41e1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548b757f14084cc0a560ece4837af23f",
            "placeholder": "​",
            "style": "IPY_MODEL_eb38dfab070d48fda05de71827cee9ed",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0fab063690a74515b76368f1f934a9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49df4268322c401b9c221d81d76bac51",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_159cf226f98642eea77a83f874287058",
            "value": 10
          }
        },
        "3d08943d5399430aa7e03d0753c6290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92354de507734d51af170d004038b20f",
            "placeholder": "​",
            "style": "IPY_MODEL_bbb65e7c3ef4488dae6bb33f5a9da7f6",
            "value": " 10/10 [00:13&lt;00:00,  1.17s/it]"
          }
        },
        "2dff1f3de0854e08b80e5a7251411013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548b757f14084cc0a560ece4837af23f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb38dfab070d48fda05de71827cee9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49df4268322c401b9c221d81d76bac51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "159cf226f98642eea77a83f874287058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92354de507734d51af170d004038b20f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbb65e7c3ef4488dae6bb33f5a9da7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2174a8780589407381c329d1f4810249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f2b481b579b4161aa91d2e536f6c0a0",
              "IPY_MODEL_5a8f21dbbc534de4938033444203926d",
              "IPY_MODEL_bc8d898a448342d4b1d04afe60bd32ed"
            ],
            "layout": "IPY_MODEL_edd4f4799063423f818fb43b4251536b"
          }
        },
        "3f2b481b579b4161aa91d2e536f6c0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4671db82a0314f71820bf6905340b884",
            "placeholder": "​",
            "style": "IPY_MODEL_e03e0fd9685e439e96de1b67a40dc812",
            "value": "adapter_config.json: 100%"
          }
        },
        "5a8f21dbbc534de4938033444203926d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804037a6b8ac4ee18d63f90436649e41",
            "max": 724,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97e818f31749491cb1e16cbc73b85d8a",
            "value": 724
          }
        },
        "bc8d898a448342d4b1d04afe60bd32ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2709437ffa8442a99104138d9f507e12",
            "placeholder": "​",
            "style": "IPY_MODEL_259b9be7793146188f28031be91ce8cd",
            "value": " 724/724 [00:00&lt;00:00, 64.7kB/s]"
          }
        },
        "edd4f4799063423f818fb43b4251536b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4671db82a0314f71820bf6905340b884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03e0fd9685e439e96de1b67a40dc812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "804037a6b8ac4ee18d63f90436649e41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97e818f31749491cb1e16cbc73b85d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2709437ffa8442a99104138d9f507e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259b9be7793146188f28031be91ce8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1978bf53524d4297ad9a65d8c7e80651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac2344eb69ff4dd9a65fa10bd6722cf6",
              "IPY_MODEL_2df9e97f60024a55a29cd515a3bf4fc7",
              "IPY_MODEL_71fe0928ebc645738824c389d70fe68a"
            ],
            "layout": "IPY_MODEL_e11156839adb4a8eb74f1ed6655fa71c"
          }
        },
        "ac2344eb69ff4dd9a65fa10bd6722cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b251f3ffde74c148e5ccf6a11b539fc",
            "placeholder": "​",
            "style": "IPY_MODEL_e93b8d9464cc47f6ad60b879062606bd",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "2df9e97f60024a55a29cd515a3bf4fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15371cd6cdce4abd816df34a74089d46",
            "max": 2060735440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b28bbb40cbd2422ca21c779fe5620a9f",
            "value": 2060735440
          }
        },
        "71fe0928ebc645738824c389d70fe68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5020cbe736604e4aaa729c62b50a432b",
            "placeholder": "​",
            "style": "IPY_MODEL_6aa7b5dd564441e6a5d7a2e27f0933a0",
            "value": " 2.06G/2.06G [00:48&lt;00:00, 41.7MB/s]"
          }
        },
        "e11156839adb4a8eb74f1ed6655fa71c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b251f3ffde74c148e5ccf6a11b539fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e93b8d9464cc47f6ad60b879062606bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15371cd6cdce4abd816df34a74089d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28bbb40cbd2422ca21c779fe5620a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5020cbe736604e4aaa729c62b50a432b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa7b5dd564441e6a5d7a2e27f0933a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc1b2928a9244fe8368570d1ff3197a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48658b28b2544645b32ade2931a9372c",
              "IPY_MODEL_aa40eb54ab3c43df80b4dfcc4e7ceb30",
              "IPY_MODEL_77ad289e5bf04579b650e33ea28feae9"
            ],
            "layout": "IPY_MODEL_cea15085c8ee4e8a878674a5e06e12ee"
          }
        },
        "48658b28b2544645b32ade2931a9372c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0d0ee5fc84414d801cae92cc0ff31a",
            "placeholder": "​",
            "style": "IPY_MODEL_83998c3e35144cc7b72a99eac813a54e",
            "value": "Answering Questions: 100%"
          }
        },
        "aa40eb54ab3c43df80b4dfcc4e7ceb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_713bcf1f2da64e508f9da93c73724d35",
            "max": 98,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3300103faaa4598bb116db77bf83398",
            "value": 98
          }
        },
        "77ad289e5bf04579b650e33ea28feae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29fb1cd1182342598da7b2badd7d104b",
            "placeholder": "​",
            "style": "IPY_MODEL_f2976ac4cb94447c9b2f49740ef2bd29",
            "value": " 98/98 [51:52&lt;00:00, 41.47s/it]"
          }
        },
        "cea15085c8ee4e8a878674a5e06e12ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc0d0ee5fc84414d801cae92cc0ff31a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83998c3e35144cc7b72a99eac813a54e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "713bcf1f2da64e508f9da93c73724d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3300103faaa4598bb116db77bf83398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29fb1cd1182342598da7b2badd7d104b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2976ac4cb94447c9b2f49740ef2bd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}